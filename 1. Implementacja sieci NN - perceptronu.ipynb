{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testowe dane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XE0TsuRnjnna"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_train=np.array([[10,11], [20,30], [5,4], [8,20], [22, 10], [9, 10], [5, 17], [5, 50], [50,5], [3,4], [6,7], [-10,10], [-10,1]])\n",
    "y_train=np.array([0,1, 0, 1, 0, 0, 1,1,0,0,0, 1,1])\n",
    "assert len(X_train)==len(y_train)\n",
    "\n",
    "\n",
    "X_test=np.array([[0,10], [20,30], [-20, 1], [19,20], [10,5], [2,1]])\n",
    "y_test=np.array([1,1,1,0,0,0])\n",
    "assert len(X_test)==len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementacja perceptronu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    \n",
    "    def __init__(self, num_features, num_epoch = 1000, learning_rate = 0.01):\n",
    "        self.num_features = num_features\n",
    "        self.num_epoch = num_epoch\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weights = np.random.normal(0, 1, self.num_features + 1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def sigmoid(x):\n",
    "        return 1.0 / (1.0 + np.exp(-x))\n",
    "    \n",
    "    def __forward(self, x):\n",
    "        y_prob = self.sigmoid(np.dot(x, self.weights[1:]) + self.weights[0])\n",
    "        return y_prob\n",
    "    \n",
    "    def train(self, X, Y, X_test, Y_test):\n",
    "        \n",
    "        for epoch in range(self.num_epoch):\n",
    "            loss = 0\n",
    "            y_true = 0\n",
    "            \n",
    "            for x, y in zip(X, Y):\n",
    "                y_prob = self.__forward(x)\n",
    "                y_pred = 1 if y_prob > 0.5 else 0\n",
    "                if y_pred == y:\n",
    "                    y_true += 1\n",
    "                loss += 0.5 * (y - y_prob) ** 2\n",
    "                self.weights[1:] += self.learning_rate * (y - y_prob) * y_prob * (1 - y_prob) * x\n",
    "                self.weights[0] += self.learning_rate * (y - y_prob) * y_prob * (1 - y_prob)\n",
    "                \n",
    "            pred = self.predict(X_test)\n",
    "            acc = sum([ y == y_ for y, y_ in zip(pred, Y_test)]) / Y_test.shape[0]\n",
    "            \n",
    "            print('Epoch:', str(epoch + 1), '/', str(self.num_epoch), '|', 'loss:', loss, '|',  'train accuracy:', round(y_true / X.shape[0] * 100, 2), '%', '|', 'test accuracy:', round(acc * 100, 2), '%.')\n",
    "           \n",
    "    def predict(self, X):\n",
    "        y_prob = self.__forward(X)\n",
    "        vfunc = np.vectorize(lambda x: 1 if x > 0.5 else 0)\n",
    "        return vfunc(y_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trenowanie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text/html": [
      "Epoch: 1 / 1000 | loss: 2.363118186125232 | train accuracy: 61.54 % | test accuracy: 66.67 %.\n",
      "Epoch: 2 / 1000 | loss: 2.2936886741316957 | train accuracy: 61.54 % | test accuracy: 66.67 %.\n",
      "Epoch: 3 / 1000 | loss: 2.2292095182952765 | train accuracy: 61.54 % | test accuracy: 66.67 %.\n",
      "Epoch: 4 / 1000 | loss: 2.1753585508745323 | train accuracy: 69.23 % | test accuracy: 66.67 %.\n",
      "Epoch: 5 / 1000 | loss: 2.1344719858962464 | train accuracy: 69.23 % | test accuracy: 66.67 %.\n",
      "Epoch: 6 / 1000 | loss: 2.104768401017771 | train accuracy: 69.23 % | test accuracy: 66.67 %.\n",
      "Epoch: 7 / 1000 | loss: 2.0829638663002643 | train accuracy: 69.23 % | test accuracy: 66.67 %.\n",
      "Epoch: 8 / 1000 | loss: 2.066177473039672 | train accuracy: 69.23 % | test accuracy: 66.67 %.\n",
      "Epoch: 9 / 1000 | loss: 2.0522976525846137 | train accuracy: 69.23 % | test accuracy: 66.67 %.\n",
      "Epoch: 10 / 1000 | loss: 2.03971536779639 | train accuracy: 69.23 % | test accuracy: 66.67 %.\n",
      "Epoch: 11 / 1000 | loss: 2.0268946145115327 | train accuracy: 69.23 % | test accuracy: 66.67 %.\n",
      "Epoch: 12 / 1000 | loss: 2.011668773818122 | train accuracy: 69.23 % | test accuracy: 66.67 %.\n",
      "Epoch: 13 / 1000 | loss: 1.9892071693568687 | train accuracy: 69.23 % | test accuracy: 66.67 %.\n",
      "Epoch: 14 / 1000 | loss: 1.9413938230074967 | train accuracy: 69.23 % | test accuracy: 83.33 %.\n",
      "Epoch: 15 / 1000 | loss: 1.707863705642515 | train accuracy: 61.54 % | test accuracy: 83.33 %.\n",
      "Epoch: 16 / 1000 | loss: 1.01391154269977 | train accuracy: 76.92 % | test accuracy: 66.67 %.\n",
      "Epoch: 17 / 1000 | loss: 0.9373510267617564 | train accuracy: 84.62 % | test accuracy: 66.67 %.\n",
      "Epoch: 18 / 1000 | loss: 0.9056577383878663 | train accuracy: 84.62 % | test accuracy: 66.67 %.\n",
      "Epoch: 19 / 1000 | loss: 0.8876366399816215 | train accuracy: 84.62 % | test accuracy: 66.67 %.\n",
      "Epoch: 20 / 1000 | loss: 0.8730579553045535 | train accuracy: 84.62 % | test accuracy: 66.67 %.\n",
      "Epoch: 21 / 1000 | loss: 0.8590120939494555 | train accuracy: 84.62 % | test accuracy: 66.67 %.\n",
      "Epoch: 22 / 1000 | loss: 0.8449482490533404 | train accuracy: 76.92 % | test accuracy: 83.33 %.\n",
      "Epoch: 23 / 1000 | loss: 0.8310989450594031 | train accuracy: 76.92 % | test accuracy: 83.33 %.\n",
      "Epoch: 24 / 1000 | loss: 0.8177428488729065 | train accuracy: 76.92 % | test accuracy: 83.33 %.\n",
      "Epoch: 25 / 1000 | loss: 0.8049764987146916 | train accuracy: 76.92 % | test accuracy: 83.33 %.\n",
      "Epoch: 26 / 1000 | loss: 0.7927614779324562 | train accuracy: 76.92 % | test accuracy: 83.33 %.\n",
      "Epoch: 27 / 1000 | loss: 0.7810151616459201 | train accuracy: 84.62 % | test accuracy: 83.33 %.\n",
      "Epoch: 28 / 1000 | loss: 0.7696599070367437 | train accuracy: 84.62 % | test accuracy: 100.0 %.\n",
      "Epoch: 29 / 1000 | loss: 0.7586369097351223 | train accuracy: 84.62 % | test accuracy: 100.0 %.\n",
      "Epoch: 30 / 1000 | loss: 0.7479050258007582 | train accuracy: 84.62 % | test accuracy: 100.0 %.\n",
      "Epoch: 31 / 1000 | loss: 0.7374359388140961 | train accuracy: 84.62 % | test accuracy: 100.0 %.\n",
      "Epoch: 32 / 1000 | loss: 0.7272097480654305 | train accuracy: 84.62 % | test accuracy: 100.0 %.\n",
      "Epoch: 33 / 1000 | loss: 0.717211855816027 | train accuracy: 84.62 % | test accuracy: 100.0 %.\n",
      "Epoch: 34 / 1000 | loss: 0.7074310014333688 | train accuracy: 84.62 % | test accuracy: 100.0 %.\n",
      "Epoch: 35 / 1000 | loss: 0.6978580858782344 | train accuracy: 84.62 % | test accuracy: 100.0 %.\n",
      "Epoch: 36 / 1000 | loss: 0.6884854800863879 | train accuracy: 84.62 % | test accuracy: 100.0 %.\n",
      "Epoch: 37 / 1000 | loss: 0.6793066097194529 | train accuracy: 84.62 % | test accuracy: 100.0 %.\n",
      "Epoch: 38 / 1000 | loss: 0.6703156924434549 | train accuracy: 84.62 % | test accuracy: 100.0 %.\n",
      "Epoch: 39 / 1000 | loss: 0.6615075597765612 | train accuracy: 84.62 % | test accuracy: 100.0 %.\n",
      "Epoch: 40 / 1000 | loss: 0.6528775281240221 | train accuracy: 84.62 % | test accuracy: 100.0 %.\n",
      "Epoch: 41 / 1000 | loss: 0.6444213008589793 | train accuracy: 84.62 % | test accuracy: 100.0 %.\n",
      "Epoch: 42 / 1000 | loss: 0.6361348918301604 | train accuracy: 84.62 % | test accuracy: 100.0 %.\n",
      "Epoch: 43 / 1000 | loss: 0.6280145647488421 | train accuracy: 84.62 % | test accuracy: 100.0 %.\n",
      "Epoch: 44 / 1000 | loss: 0.6200567848822255 | train accuracy: 84.62 % | test accuracy: 100.0 %.\n",
      "Epoch: 45 / 1000 | loss: 0.6122581805150229 | train accuracy: 84.62 % | test accuracy: 100.0 %.\n",
      "Epoch: 46 / 1000 | loss: 0.6046155122549921 | train accuracy: 84.62 % | test accuracy: 100.0 %.\n",
      "Epoch: 47 / 1000 | loss: 0.59712564867091 | train accuracy: 84.62 % | test accuracy: 100.0 %.\n",
      "Epoch: 48 / 1000 | loss: 0.5897855470544934 | train accuracy: 84.62 % | test accuracy: 100.0 %.\n",
      "Epoch: 49 / 1000 | loss: 0.5825922383313091 | train accuracy: 84.62 % | test accuracy: 100.0 %.\n",
      "Epoch: 50 / 1000 | loss: 0.5755428153300028 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 51 / 1000 | loss: 0.5686344237664848 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 52 / 1000 | loss: 0.5618642554181381 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 53 / 1000 | loss: 0.5552295430590058 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 54 / 1000 | loss: 0.5487275568047417 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 55 / 1000 | loss: 0.5423556015795769 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 56 / 1000 | loss: 0.5361110154695033 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 57 / 1000 | loss: 0.5299911687684506 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 58 / 1000 | loss: 0.5239934635593092 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 59 / 1000 | loss: 0.5181153337005306 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 60 / 1000 | loss: 0.5123542451129198 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 61 / 1000 | loss: 0.5067076962809687 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 62 / 1000 | loss: 0.501173218899454 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 63 / 1000 | loss: 0.49574837860954446 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 64 / 1000 | loss: 0.4904307757799294 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 65 / 1000 | loss: 0.4852180462977492 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 66 / 1000 | loss: 0.4801078623418433 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 67 / 1000 | loss: 0.47509793311717186 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 68 / 1000 | loss: 0.4701860055345312 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 69 / 1000 | loss: 0.46536986482400644 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 70 / 1000 | loss: 0.4606473350741217 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 71 / 1000 | loss: 0.4560162796915436 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 72 / 1000 | loss: 0.4514746017785484 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 73 / 1000 | loss: 0.4470202444272908 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 74 / 1000 | loss: 0.4426511909314701 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 75 / 1000 | loss: 0.43836546491711187 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 76 / 1000 | loss: 0.4341611303951206 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 77 / 1000 | loss: 0.4300362917389337 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 78 / 1000 | loss: 0.42598909359111586 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 79 / 1000 | loss: 0.42201772070307536 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 80 / 1000 | loss: 0.41812039771230614 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 81 / 1000 | loss: 0.4142953888617104 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 82 / 1000 | loss: 0.41054099766554736 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 83 / 1000 | loss: 0.4068555665265828 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 84 / 1000 | loss: 0.403237476308894 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 85 / 1000 | loss: 0.39968514587068216 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 86 / 1000 | loss: 0.3961970315613068 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 87 / 1000 | loss: 0.3927716266865492 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 88 / 1000 | loss: 0.38940746094594675 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 89 / 1000 | loss: 0.3861030998458419 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 90 / 1000 | loss: 0.38285714409154936 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 91 / 1000 | loss: 0.3796682289618698 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 92 / 1000 | loss: 0.3765350236689434 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 93 / 1000 | loss: 0.373456230706236 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 94 / 1000 | loss: 0.3704305851872454 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 95 / 1000 | loss: 0.3674568541773106 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 96 / 1000 | loss: 0.3645338360207326 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 97 / 1000 | loss: 0.36166035966520327 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 98 / 1000 | loss: 0.3588352839853928 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 99 / 1000 | loss: 0.35605749710736045 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 100 / 1000 | loss: 0.35332591573530087 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 101 / 1000 | loss: 0.35063948448200144 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 102 / 1000 | loss: 0.34799717520421947 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 103 / 1000 | loss: 0.34539798634409513 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 104 / 1000 | loss: 0.34284094227755335 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 105 / 1000 | loss: 0.340325092670583 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 106 / 1000 | loss: 0.3378495118441164 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 107 / 1000 | loss: 0.3354132981482011 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 108 / 1000 | loss: 0.33301557334600956 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 109 / 1000 | loss: 0.3306554820081893 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 110 / 1000 | loss: 0.3283321909179526 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 111 / 1000 | loss: 0.32604488848726115 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 112 / 1000 | loss: 0.323792784184366 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 113 / 1000 | loss: 0.32157510797294475 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 114 / 1000 | loss: 0.3193911097629822 | train accuracy: 92.31 % | test accuracy: 100.0 %.\n",
      "Epoch: 115 / 1000 | loss: 0.3172400588735272 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 116 / 1000 | loss: 0.3151212435073999 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 117 / 1000 | loss: 0.3130339702378809 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 118 / 1000 | loss: 0.3109775635073941 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 119 / 1000 | loss: 0.3089513651381393 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 120 / 1000 | loss: 0.306954733854637 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 121 / 1000 | loss: 0.3049870448180791 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 122 / 1000 | loss: 0.3030476891724032 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 123 / 1000 | loss: 0.30113607360194916 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 124 / 1000 | loss: 0.299251619900566 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 125 / 1000 | loss: 0.29739376455200944 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 126 / 1000 | loss: 0.29556195832145954 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 127 / 1000 | loss: 0.29375566585797885 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 128 / 1000 | loss: 0.2919743653077276 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 129 / 1000 | loss: 0.290217547937724 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 130 / 1000 | loss: 0.2884847177699586 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 131 / 1000 | loss: 0.2867753912256513 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 132 / 1000 | loss: 0.2850890967794303 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 133 / 1000 | loss: 0.28342537462322326 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 134 / 1000 | loss: 0.2817837763396424 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 135 / 1000 | loss: 0.28016386458464276 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 136 / 1000 | loss: 0.27856521277922774 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 137 / 1000 | loss: 0.2769874048099911 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 138 / 1000 | loss: 0.27543003473827327 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 139 / 1000 | loss: 0.2738927065177081 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 140 / 1000 | loss: 0.2723750337199531 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 141 / 1000 | loss: 0.2708766392683797 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 142 / 1000 | loss: 0.2693971551795211 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 143 / 1000 | loss: 0.2679362223120605 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 144 / 1000 | loss: 0.266493490123162 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 145 / 1000 | loss: 0.2650686164319312 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 146 / 1000 | loss: 0.2636612671898222 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 147 / 1000 | loss: 0.2622711162577769 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 148 / 1000 | loss: 0.260897845189923 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 149 / 1000 | loss: 0.2595411430236286 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 150 / 1000 | loss: 0.258200706075742 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 151 / 1000 | loss: 0.2568762377448278 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 152 / 1000 | loss: 0.2555674483192286 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 153 / 1000 | loss: 0.2542740547907825 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 154 / 1000 | loss: 0.2529957806740221 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 155 / 1000 | loss: 0.25173235583070536 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 156 / 1000 | loss: 0.2504835162995009 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 157 / 1000 | loss: 0.24924900413069154 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 158 / 1000 | loss: 0.24802856722573724 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 159 / 1000 | loss: 0.24682195918154065 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 160 / 1000 | loss: 0.24562893913930206 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 161 / 1000 | loss: 0.2444492716377837 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 162 / 1000 | loss: 0.2432827264708914 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 163 / 1000 | loss: 0.2421290785494069 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 164 / 1000 | loss: 0.2409881077667711 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 165 / 1000 | loss: 0.23985959886877214 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 166 / 1000 | loss: 0.23874334132703934 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 167 / 1000 | loss: 0.237639129216205 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 168 / 1000 | loss: 0.23654676109464448 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 169 / 1000 | loss: 0.23546603988866138 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 170 / 1000 | loss: 0.23439677278003374 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 171 / 1000 | loss: 0.23333877109679976 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 172 / 1000 | loss: 0.23229185020719212 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 173 / 1000 | loss: 0.23125582941662912 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 174 / 1000 | loss: 0.23023053186765366 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 175 / 1000 | loss: 0.2292157844427445 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 176 / 1000 | loss: 0.22821141766990297 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 177 / 1000 | loss: 0.22721726563093061 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 178 / 1000 | loss: 0.2262331658723186 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 179 / 1000 | loss: 0.22525895931866594 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 180 / 1000 | loss: 0.224294490188546 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 181 / 1000 | loss: 0.22333960591275687 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 182 / 1000 | loss: 0.2223941570548664 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 183 / 1000 | loss: 0.22145799723399778 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 184 / 1000 | loss: 0.2205309830497763 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 185 / 1000 | loss: 0.2196129740093743 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 186 / 1000 | loss: 0.2187038324565943 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 187 / 1000 | loss: 0.2178034235029218 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 188 / 1000 | loss: 0.21691161496049094 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 189 / 1000 | loss: 0.21602827727690524 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 190 / 1000 | loss: 0.21515328347186055 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 191 / 1000 | loss: 0.21428650907550362 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 192 / 1000 | loss: 0.21342783206848928 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 193 / 1000 | loss: 0.21257713282367463 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 194 / 1000 | loss: 0.21173429404940478 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 195 / 1000 | loss: 0.2108992007343399 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 196 / 1000 | loss: 0.21007174009378243 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 197 / 1000 | loss: 0.20925180151745057 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 198 / 1000 | loss: 0.20843927651866576 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 199 / 1000 | loss: 0.20763405868490462 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 200 / 1000 | loss: 0.20683604362967323 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 201 / 1000 | loss: 0.2060451289456725 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 202 / 1000 | loss: 0.20526121415920903 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 203 / 1000 | loss: 0.20448420068581813 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 204 / 1000 | loss: 0.2037139917870624 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 205 / 1000 | loss: 0.20295049252846845 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 206 / 1000 | loss: 0.20219360973857736 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 207 / 1000 | loss: 0.20144325196906124 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 208 / 1000 | loss: 0.20069932945589072 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 209 / 1000 | loss: 0.19996175408151365 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 210 / 1000 | loss: 0.1992304393380113 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 211 / 1000 | loss: 0.19850530029122154 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 212 / 1000 | loss: 0.1977862535457744 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 213 / 1000 | loss: 0.19707321721104368 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 214 / 1000 | loss: 0.19636611086795946 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 215 / 1000 | loss: 0.19566485553667823 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 216 / 1000 | loss: 0.19496937364507647 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 217 / 1000 | loss: 0.19427958899804346 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 218 / 1000 | loss: 0.19359542674755556 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 219 / 1000 | loss: 0.19291681336350516 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 220 / 1000 | loss: 0.1922436766052637 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 221 / 1000 | loss: 0.1915759454939629 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 222 / 1000 | loss: 0.19091355028546536 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 223 / 1000 | loss: 0.19025642244401175 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 224 / 1000 | loss: 0.18960449461652418 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 225 / 1000 | loss: 0.18895770060754538 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 226 / 1000 | loss: 0.1883159753547979 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 227 / 1000 | loss: 0.1876792549053481 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 228 / 1000 | loss: 0.18704747639234662 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 229 / 1000 | loss: 0.1864205780123515 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 230 / 1000 | loss: 0.185798499003194 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 231 / 1000 | loss: 0.18518117962238562 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 232 / 1000 | loss: 0.1845685611260526 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 233 / 1000 | loss: 0.18396058574837332 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 234 / 1000 | loss: 0.18335719668151648 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 235 / 1000 | loss: 0.1827583380560556 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 236 / 1000 | loss: 0.1821639549218573 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 237 / 1000 | loss: 0.18157399322942325 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 238 / 1000 | loss: 0.18098839981167458 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 239 / 1000 | loss: 0.1804071223661707 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 240 / 1000 | loss: 0.17983010943774635 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 241 / 1000 | loss: 0.17925731040155785 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 242 / 1000 | loss: 0.17868867544652728 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 243 / 1000 | loss: 0.1781241555591765 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 244 / 1000 | loss: 0.17756370250783213 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 245 / 1000 | loss: 0.17700726882720474 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 246 / 1000 | loss: 0.17645480780332157 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 247 / 1000 | loss: 0.17590627345880727 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 248 / 1000 | loss: 0.17536162053850513 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 249 / 1000 | loss: 0.17482080449542634 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 250 / 1000 | loss: 0.17428378147702336 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 251 / 1000 | loss: 0.1737505083117741 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 252 / 1000 | loss: 0.17322094249607004 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 253 / 1000 | loss: 0.17269504218140616 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 254 / 1000 | loss: 0.17217276616185526 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 255 / 1000 | loss: 0.17165407386182513 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 256 / 1000 | loss: 0.17113892532409528 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 257 / 1000 | loss: 0.1706272811981135 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 258 / 1000 | loss: 0.1701191027285587 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 259 / 1000 | loss: 0.16961435174415804 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 260 / 1000 | loss: 0.16911299064674848 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 261 / 1000 | loss: 0.16861498240058395 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 262 / 1000 | loss: 0.1681202905218728 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 263 / 1000 | loss: 0.16762887906855228 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 264 / 1000 | loss: 0.1671407126302785 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 265 / 1000 | loss: 0.16665575631864085 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 266 / 1000 | loss: 0.16617397575758483 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 267 / 1000 | loss: 0.1656953370740486 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 268 / 1000 | loss: 0.16521980688879292 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 269 / 1000 | loss: 0.1647473523074354 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 270 / 1000 | loss: 0.1642779409116764 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 271 / 1000 | loss: 0.1638115407507096 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 272 / 1000 | loss: 0.163348120332818 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 273 / 1000 | loss: 0.16288764861714913 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 274 / 1000 | loss: 0.16243009500566274 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 275 / 1000 | loss: 0.16197542933525041 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 276 / 1000 | loss: 0.16152362187002 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 277 / 1000 | loss: 0.16107464329374394 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 278 / 1000 | loss: 0.160628464702461 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 279 / 1000 | loss: 0.16018505759724075 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 280 / 1000 | loss: 0.15974439387708808 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 281 / 1000 | loss: 0.15930644583200562 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 282 / 1000 | loss: 0.15887118613618853 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 283 / 1000 | loss: 0.15843858784137269 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 284 / 1000 | loss: 0.15800862437030488 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 285 / 1000 | loss: 0.15758126951036072 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 286 / 1000 | loss: 0.1571564974072815 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 287 / 1000 | loss: 0.15673428255904556 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 288 / 1000 | loss: 0.15631459980986326 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 289 / 1000 | loss: 0.15589742434428844 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 290 / 1000 | loss: 0.15548273168145815 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 291 / 1000 | loss: 0.1550704976694366 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 292 / 1000 | loss: 0.15466069847968256 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 293 / 1000 | loss: 0.1542533106016219 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 294 / 1000 | loss: 0.15384831083732933 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 295 / 1000 | loss: 0.15344567629631792 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 296 / 1000 | loss: 0.15304538439042759 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 297 / 1000 | loss: 0.1526474128288203 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 298 / 1000 | loss: 0.1522517396130676 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 299 / 1000 | loss: 0.1518583430323398 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 300 / 1000 | loss: 0.1514672016586866 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 301 / 1000 | loss: 0.15107829434240966 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 302 / 1000 | loss: 0.15069160020752712 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 303 / 1000 | loss: 0.15030709864732425 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 304 / 1000 | loss: 0.14992476931999157 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 305 / 1000 | loss: 0.14954459214434634 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 306 / 1000 | loss: 0.1491665472956344 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 307 / 1000 | loss: 0.14879061520141787 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 308 / 1000 | loss: 0.1484167765375354 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 309 / 1000 | loss: 0.14804501222414396 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 310 / 1000 | loss: 0.14767530342183205 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 311 / 1000 | loss: 0.14730763152781023 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 312 / 1000 | loss: 0.14694197817216995 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 313 / 1000 | loss: 0.14657832521421796 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 314 / 1000 | loss: 0.1462166547388721 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 315 / 1000 | loss: 0.14585694905313262 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 316 / 1000 | loss: 0.14549919068261374 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 317 / 1000 | loss: 0.1451433623681417 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 318 / 1000 | loss: 0.14478944706241623 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 319 / 1000 | loss: 0.14443742792673392 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 320 / 1000 | loss: 0.1440872883277706 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 321 / 1000 | loss: 0.14373901183442506 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 322 / 1000 | loss: 0.14339258221471987 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 323 / 1000 | loss: 0.1430479834327558 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 324 / 1000 | loss: 0.1427051996457291 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 325 / 1000 | loss: 0.14236421520099485 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 326 / 1000 | loss: 0.14202501463319042 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 327 / 1000 | loss: 0.14168758266140397 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 328 / 1000 | loss: 0.14135190418640176 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 329 / 1000 | loss: 0.14101796428790062 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 330 / 1000 | loss: 0.1406857482218872 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 331 / 1000 | loss: 0.14035524141799344 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 332 / 1000 | loss: 0.14002642947690908 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 333 / 1000 | loss: 0.13969929816784615 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 334 / 1000 | loss: 0.13937383342604862 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 335 / 1000 | loss: 0.13905002135034247 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 336 / 1000 | loss: 0.13872784820073064 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 337 / 1000 | loss: 0.13840730039603333 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 338 / 1000 | loss: 0.1380883645115632 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 339 / 1000 | loss: 0.13777102727684792 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 340 / 1000 | loss: 0.13745527557338877 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 341 / 1000 | loss: 0.13714109643245853 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 342 / 1000 | loss: 0.13682847703293716 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 343 / 1000 | loss: 0.1365174046991872 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 344 / 1000 | loss: 0.13620786689896397 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 345 / 1000 | loss: 0.1358998512413622 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 346 / 1000 | loss: 0.1355933454747964 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 347 / 1000 | loss: 0.13528833748501987 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 348 / 1000 | loss: 0.13498481529317036 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 349 / 1000 | loss: 0.13468276705385857 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 350 / 1000 | loss: 0.13438218105328123 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 351 / 1000 | loss: 0.1340830457073674 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 352 / 1000 | loss: 0.13378534955996088 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 353 / 1000 | loss: 0.1334890812810266 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 354 / 1000 | loss: 0.13319422966489206 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 355 / 1000 | loss: 0.13290078362851668 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 356 / 1000 | loss: 0.1326087322097874 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 357 / 1000 | loss: 0.13231806456584774 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 358 / 1000 | loss: 0.13202876997145116 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 359 / 1000 | loss: 0.13174083781734056 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 360 / 1000 | loss: 0.13145425760866003 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 361 / 1000 | loss: 0.13116901896338476 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 362 / 1000 | loss: 0.13088511161078487 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 363 / 1000 | loss: 0.13060252538990905 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 364 / 1000 | loss: 0.13032125024809385 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 365 / 1000 | loss: 0.13004127623949863 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 366 / 1000 | loss: 0.12976259352366545 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 367 / 1000 | loss: 0.1294851923640976 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 368 / 1000 | loss: 0.12920906312686534 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 369 / 1000 | loss: 0.12893419627923344 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 370 / 1000 | loss: 0.12866058238830938 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 371 / 1000 | loss: 0.12838821211971385 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 372 / 1000 | loss: 0.12811707623627402 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 373 / 1000 | loss: 0.12784716559673476 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 374 / 1000 | loss: 0.12757847115449245 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 375 / 1000 | loss: 0.1273109839563497 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 376 / 1000 | loss: 0.12704469514128588 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 377 / 1000 | loss: 0.1267795959392528 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 378 / 1000 | loss: 0.12651567766998384 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 379 / 1000 | loss: 0.1262529317418245 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 380 / 1000 | loss: 0.1259913496505826 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 381 / 1000 | loss: 0.12573092297839347 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 382 / 1000 | loss: 0.12547164339260286 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 383 / 1000 | loss: 0.1252135026446728 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 384 / 1000 | loss: 0.12495649256909502 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 385 / 1000 | loss: 0.12470060508233081 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 386 / 1000 | loss: 0.12444583218175934 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 387 / 1000 | loss: 0.12419216594464713 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 388 / 1000 | loss: 0.12393959852713281 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 389 / 1000 | loss: 0.12368812216322492 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 390 / 1000 | loss: 0.12343772916381555 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 391 / 1000 | loss: 0.1231884119157138 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 392 / 1000 | loss: 0.12294016288068631 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 393 / 1000 | loss: 0.12269297459451786 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 394 / 1000 | loss: 0.12244683966608433 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 395 / 1000 | loss: 0.12220175077643951 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 396 / 1000 | loss: 0.12195770067791674 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 397 / 1000 | loss: 0.12171468219324183 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 398 / 1000 | loss: 0.12147268821466235 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 399 / 1000 | loss: 0.12123171170308608 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 400 / 1000 | loss: 0.12099174568723764 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 401 / 1000 | loss: 0.1207527832628206 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 402 / 1000 | loss: 0.12051481759169931 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 403 / 1000 | loss: 0.12027784190108795 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 404 / 1000 | loss: 0.12004184948275211 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 405 / 1000 | loss: 0.11980683369222471 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 406 / 1000 | loss: 0.11957278794803132 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 407 / 1000 | loss: 0.11933970573092632 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 408 / 1000 | loss: 0.11910758058314158 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 409 / 1000 | loss: 0.11887640610764771 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 410 / 1000 | loss: 0.11864617596741979 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 411 / 1000 | loss: 0.11841688388472177 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 412 / 1000 | loss: 0.11818852364039653 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 413 / 1000 | loss: 0.11796108907316506 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 414 / 1000 | loss: 0.11773457407894038 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 415 / 1000 | loss: 0.1175089726101474 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 416 / 1000 | loss: 0.11728427867505437 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 417 / 1000 | loss: 0.1170604863371121 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 418 / 1000 | loss: 0.11683758971430605 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 419 / 1000 | loss: 0.11661558297851275 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 420 / 1000 | loss: 0.11639446035487037 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 421 / 1000 | loss: 0.11617421612115553 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 422 / 1000 | loss: 0.11595484460716654 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 423 / 1000 | loss: 0.11573634019412272 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 424 / 1000 | loss: 0.1155186973140638 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 425 / 1000 | loss: 0.11530191044926211 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 426 / 1000 | loss: 0.11508597413164362 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 427 / 1000 | loss: 0.11487088294221491 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 428 / 1000 | loss: 0.11465663151049928 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 429 / 1000 | loss: 0.11444321451398003 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 430 / 1000 | loss: 0.11423062667755135 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 431 / 1000 | loss: 0.11401886277297914 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 432 / 1000 | loss: 0.11380791761836612 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 433 / 1000 | loss: 0.11359778607762432 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 434 / 1000 | loss: 0.11338846305995927 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 435 / 1000 | loss: 0.11317994351935598 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 436 / 1000 | loss: 0.1129722224540736 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 437 / 1000 | loss: 0.11276529490614859 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 438 / 1000 | loss: 0.1125591559609041 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 439 / 1000 | loss: 0.11235380074646376 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 440 / 1000 | loss: 0.1121492244332739 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 441 / 1000 | loss: 0.11194542223363334 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 442 / 1000 | loss: 0.11174238940122781 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 443 / 1000 | loss: 0.11154012123066893 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 444 / 1000 | loss: 0.11133861305704564 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 445 / 1000 | loss: 0.11113786025547334 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 446 / 1000 | loss: 0.1109378582406555 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 447 / 1000 | loss: 0.11073860246644779 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 448 / 1000 | loss: 0.11054008842543064 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 449 / 1000 | loss: 0.11034231164848421 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 450 / 1000 | loss: 0.11014526770436975 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 451 / 1000 | loss: 0.10994895219932128 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 452 / 1000 | loss: 0.10975336077663496 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 453 / 1000 | loss: 0.1095584891162685 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 454 / 1000 | loss: 0.10936433293444688 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 455 / 1000 | loss: 0.10917088798326892 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 456 / 1000 | loss: 0.1089781500503223 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 457 / 1000 | loss: 0.10878611495830423 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 458 / 1000 | loss: 0.10859477856464281 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 459 / 1000 | loss: 0.10840413676112791 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 460 / 1000 | loss: 0.10821418547354476 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 461 / 1000 | loss: 0.10802492066131188 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 462 / 1000 | loss: 0.10783633831712426 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 463 / 1000 | loss: 0.10764843446660191 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 464 / 1000 | loss: 0.10746120516794147 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 465 / 1000 | loss: 0.10727464651157352 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 466 / 1000 | loss: 0.10708875461982277 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 467 / 1000 | loss: 0.10690352564657474 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 468 / 1000 | loss: 0.10671895577694472 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 469 / 1000 | loss: 0.10653504122695129 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 470 / 1000 | loss: 0.10635177824319536 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 471 / 1000 | loss: 0.1061691631025427 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 472 / 1000 | loss: 0.10598719211180688 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 473 / 1000 | loss: 0.1058058616074443 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 474 / 1000 | loss: 0.10562516795524378 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 475 / 1000 | loss: 0.10544510755002648 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 476 / 1000 | loss: 0.10526567681534751 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 477 / 1000 | loss: 0.10508687220320066 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 478 / 1000 | loss: 0.10490869019372709 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 479 / 1000 | loss: 0.10473112729492917 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 480 / 1000 | loss: 0.10455418004238522 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 481 / 1000 | loss: 0.10437784499897014 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 482 / 1000 | loss: 0.10420211875457851 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 483 / 1000 | loss: 0.10402699792584962 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 484 / 1000 | loss: 0.10385247915590001 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 485 / 1000 | loss: 0.10367855911405456 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 486 / 1000 | loss: 0.10350523449558399 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 487 / 1000 | loss: 0.1033325020214438 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 488 / 1000 | loss: 0.10316035843801857 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 489 / 1000 | loss: 0.10298880051686553 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 490 / 1000 | loss: 0.10281782505446643 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 491 / 1000 | loss: 0.10264742887197825 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 492 / 1000 | loss: 0.10247760881498737 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 493 / 1000 | loss: 0.10230836175327013 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 494 / 1000 | loss: 0.10213968458055143 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 495 / 1000 | loss: 0.10197157421426999 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 496 / 1000 | loss: 0.10180402759534468 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 497 / 1000 | loss: 0.1016370416879437 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 498 / 1000 | loss: 0.10147061347925744 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 499 / 1000 | loss: 0.10130473997927317 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 500 / 1000 | loss: 0.10113941822055199 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 501 / 1000 | loss: 0.10097464525800987 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 502 / 1000 | loss: 0.10081041816870084 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 503 / 1000 | loss: 0.10064673405160128 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 504 / 1000 | loss: 0.10048359002739911 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 505 / 1000 | loss: 0.10032098323828358 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 506 / 1000 | loss: 0.10015891084773763 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 507 / 1000 | loss: 0.09999737004033464 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 508 / 1000 | loss: 0.09983635802153515 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 509 / 1000 | loss: 0.09967587201748743 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 510 / 1000 | loss: 0.09951590927482946 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 511 / 1000 | loss: 0.09935646706049374 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 512 / 1000 | loss: 0.09919754266151476 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 513 / 1000 | loss: 0.09903913338483805 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 514 / 1000 | loss: 0.09888123655713198 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 515 / 1000 | loss: 0.09872384952459975 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 516 / 1000 | loss: 0.09856696965279632 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 517 / 1000 | loss: 0.09841059432644779 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 518 / 1000 | loss: 0.09825472094926806 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 519 / 1000 | loss: 0.09809934694378362 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 520 / 1000 | loss: 0.09794446975115605 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 521 / 1000 | loss: 0.09779008683100954 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 522 / 1000 | loss: 0.09763619566125654 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 523 / 1000 | loss: 0.09748279373793041 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 524 / 1000 | loss: 0.09732987857501521 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 525 / 1000 | loss: 0.09717744770428152 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 526 / 1000 | loss: 0.09702549867511975 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 527 / 1000 | loss: 0.09687402905438018 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 528 / 1000 | loss: 0.09672303642621025 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 529 / 1000 | loss: 0.09657251839189668 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 530 / 1000 | loss: 0.09642247256970836 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 531 / 1000 | loss: 0.09627289659474149 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 532 / 1000 | loss: 0.09612378811876422 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 533 / 1000 | loss: 0.0959751448100679 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 534 / 1000 | loss: 0.09582696435331317 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 535 / 1000 | loss: 0.0956792444493847 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 536 / 1000 | loss: 0.09553198281524235 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 537 / 1000 | loss: 0.09538517718377675 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 538 / 1000 | loss: 0.09523882530366469 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 539 / 1000 | loss: 0.09509292493922944 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 540 / 1000 | loss: 0.09494747387029687 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 541 / 1000 | loss: 0.09480246989205943 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 542 / 1000 | loss: 0.09465791081493663 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 543 / 1000 | loss: 0.09451379446444012 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 544 / 1000 | loss: 0.09437011868103957 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 545 / 1000 | loss: 0.09422688132002899 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 546 / 1000 | loss: 0.0940840802513945 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 547 / 1000 | loss: 0.09394171335968587 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 548 / 1000 | loss: 0.09379977854388681 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 549 / 1000 | loss: 0.09365827371728702 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 550 / 1000 | loss: 0.09351719680735826 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 551 / 1000 | loss: 0.09337654575562715 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 552 / 1000 | loss: 0.0932363185175538 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 553 / 1000 | loss: 0.09309651306240886 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 554 / 1000 | loss: 0.09295712737315376 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 555 / 1000 | loss: 0.09281815944632014 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 556 / 1000 | loss: 0.09267960729189229 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 557 / 1000 | loss: 0.09254146893319141 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 558 / 1000 | loss: 0.09240374240675814 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 559 / 1000 | loss: 0.09226642576223919 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 560 / 1000 | loss: 0.09212951706227437 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 561 / 1000 | loss: 0.0919930143823837 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 562 / 1000 | loss: 0.09185691581085721 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 563 / 1000 | loss: 0.09172121944864628 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 564 / 1000 | loss: 0.09158592340925265 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 565 / 1000 | loss: 0.09145102581862379 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 566 / 1000 | loss: 0.09131652481504475 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 567 / 1000 | loss: 0.09118241854903397 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 568 / 1000 | loss: 0.0910487051832389 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 569 / 1000 | loss: 0.09091538289233345 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 570 / 1000 | loss: 0.0907824498629158 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 571 / 1000 | loss: 0.09064990429340689 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 572 / 1000 | loss: 0.09051774439395252 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 573 / 1000 | loss: 0.09038596838632246 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 574 / 1000 | loss: 0.09025457450381434 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 575 / 1000 | loss: 0.09012356099115632 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 576 / 1000 | loss: 0.08999292610441022 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 577 / 1000 | loss: 0.08986266811087962 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 578 / 1000 | loss: 0.08973278528901299 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 579 / 1000 | loss: 0.08960327592831235 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 580 / 1000 | loss: 0.08947413832924178 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 581 / 1000 | loss: 0.08934537080313516 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 582 / 1000 | loss: 0.08921697167210794 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 583 / 1000 | loss: 0.08908893926896576 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 584 / 1000 | loss: 0.0889612719371183 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 585 / 1000 | loss: 0.08883396803049053 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 586 / 1000 | loss: 0.08870702591343702 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 587 / 1000 | loss: 0.0885804439606568 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 588 / 1000 | loss: 0.08845422055710654 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 589 / 1000 | loss: 0.08832835409791968 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 590 / 1000 | loss: 0.08820284298832139 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 591 / 1000 | loss: 0.08807768564354598 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 592 / 1000 | loss: 0.0879528804887579 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 593 / 1000 | loss: 0.08782842595896875 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 594 / 1000 | loss: 0.08770432049895814 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 595 / 1000 | loss: 0.0875805625631957 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 596 / 1000 | loss: 0.0874571506157619 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 597 / 1000 | loss: 0.08733408313027059 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 598 / 1000 | loss: 0.08721135858979345 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 599 / 1000 | loss: 0.08708897548678228 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 600 / 1000 | loss: 0.08696693232299565 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 601 / 1000 | loss: 0.08684522760942275 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 602 / 1000 | loss: 0.08672385986621162 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 603 / 1000 | loss: 0.08660282762259451 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 604 / 1000 | loss: 0.08648212941681625 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 605 / 1000 | loss: 0.08636176379606336 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 606 / 1000 | loss: 0.08624172931639121 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 607 / 1000 | loss: 0.08612202454265655 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 608 / 1000 | loss: 0.0860026480484458 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 609 / 1000 | loss: 0.08588359841600728 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 610 / 1000 | loss: 0.0857648742361826 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 611 / 1000 | loss: 0.08564647410833987 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 612 / 1000 | loss: 0.08552839664030572 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 613 / 1000 | loss: 0.08541064044830009 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 614 / 1000 | loss: 0.08529320415687026 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 615 / 1000 | loss: 0.08517608639882578 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 616 / 1000 | loss: 0.0850592858151739 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 617 / 1000 | loss: 0.08494280105505729 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 618 / 1000 | loss: 0.08482663077568894 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 619 / 1000 | loss: 0.08471077364229078 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 620 / 1000 | loss: 0.08459522832803165 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 621 / 1000 | loss: 0.0844799935139661 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 622 / 1000 | loss: 0.08436506788897315 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 623 / 1000 | loss: 0.08425045014969627 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 624 / 1000 | loss: 0.0841361390004841 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 625 / 1000 | loss: 0.0840221331533316 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 626 / 1000 | loss: 0.08390843132782018 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 627 / 1000 | loss: 0.0837950322510618 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 628 / 1000 | loss: 0.08368193465763968 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 629 / 1000 | loss: 0.08356913728955274 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 630 / 1000 | loss: 0.08345663889615818 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 631 / 1000 | loss: 0.08334443823411722 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 632 / 1000 | loss: 0.08323253406733863 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 633 / 1000 | loss: 0.083120925166923 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 634 / 1000 | loss: 0.08300961031111115 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 635 / 1000 | loss: 0.08289858828522798 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 636 / 1000 | loss: 0.08278785788163052 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 637 / 1000 | loss: 0.0826774178996547 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 638 / 1000 | loss: 0.08256726714556305 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 639 / 1000 | loss: 0.08245740443249268 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 640 / 1000 | loss: 0.0823478285804039 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 641 / 1000 | loss: 0.08223853841603065 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 642 / 1000 | loss: 0.0821295327728279 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 643 / 1000 | loss: 0.08202081049092393 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 644 / 1000 | loss: 0.0819123704170686 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 645 / 1000 | loss: 0.08180421140458691 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 646 / 1000 | loss: 0.08169633231332767 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 647 / 1000 | loss: 0.0815887320096178 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 648 / 1000 | loss: 0.08148140936621277 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 649 / 1000 | loss: 0.08137436326225003 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 650 / 1000 | loss: 0.08126759258320237 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 651 / 1000 | loss: 0.08116109622083173 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 652 / 1000 | loss: 0.08105487307314167 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 653 / 1000 | loss: 0.08094892204433408 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 654 / 1000 | loss: 0.08084324204476168 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 655 / 1000 | loss: 0.08073783199088487 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 656 / 1000 | loss: 0.08063269080522614 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 657 / 1000 | loss: 0.08052781741632781 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 658 / 1000 | loss: 0.08042321075870608 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 659 / 1000 | loss: 0.08031886977280975 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 660 / 1000 | loss: 0.08021479340497674 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 661 / 1000 | loss: 0.08011098060739087 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 662 / 1000 | loss: 0.08000743033804093 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 663 / 1000 | loss: 0.07990414156067913 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 664 / 1000 | loss: 0.07980111324477812 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 665 / 1000 | loss: 0.07969834436549184 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 666 / 1000 | loss: 0.07959583390361344 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 667 / 1000 | loss: 0.07949358084553615 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 668 / 1000 | loss: 0.0793915841832136 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 669 / 1000 | loss: 0.07928984291411784 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 670 / 1000 | loss: 0.07918835604120394 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 671 / 1000 | loss: 0.07908712257286794 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 672 / 1000 | loss: 0.07898614152290882 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 673 / 1000 | loss: 0.07888541191049302 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 674 / 1000 | loss: 0.07878493276011253 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 675 / 1000 | loss: 0.07868470310155032 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 676 / 1000 | loss: 0.07858472196984187 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 677 / 1000 | loss: 0.07848498840523882 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 678 / 1000 | loss: 0.07838550145317208 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 679 / 1000 | loss: 0.07828626016421511 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 680 / 1000 | loss: 0.07818726359404894 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 681 / 1000 | loss: 0.07808851080342671 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 682 / 1000 | loss: 0.0779900008581369 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 683 / 1000 | loss: 0.07789173282896927 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 684 / 1000 | loss: 0.07779370579168005 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 685 / 1000 | loss: 0.07769591882695788 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 686 / 1000 | loss: 0.07759837102038859 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 687 / 1000 | loss: 0.07750106146242257 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 688 / 1000 | loss: 0.07740398924834092 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 689 / 1000 | loss: 0.0773071534782206 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 690 / 1000 | loss: 0.07721055325690453 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 691 / 1000 | loss: 0.07711418769396572 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 692 / 1000 | loss: 0.07701805590367684 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 693 / 1000 | loss: 0.07692215700497743 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 694 / 1000 | loss: 0.07682649012144198 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 695 / 1000 | loss: 0.07673105438124794 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 696 / 1000 | loss: 0.07663584891714564 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 697 / 1000 | loss: 0.07654087286642498 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 698 / 1000 | loss: 0.07644612537088744 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 699 / 1000 | loss: 0.07635160557681277 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 700 / 1000 | loss: 0.0762573126349307 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 701 / 1000 | loss: 0.07616324570038911 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 702 / 1000 | loss: 0.07606940393272622 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 703 / 1000 | loss: 0.07597578649583905 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 704 / 1000 | loss: 0.07588239255795566 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 705 / 1000 | loss: 0.07578922129160474 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 706 / 1000 | loss: 0.0756962718735877 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 707 / 1000 | loss: 0.07560354348494992 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 708 / 1000 | loss: 0.0755110353109515 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 709 / 1000 | loss: 0.07541874654104089 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 710 / 1000 | loss: 0.07532667636882508 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 711 / 1000 | loss: 0.07523482399204301 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 712 / 1000 | loss: 0.07514318861253795 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 713 / 1000 | loss: 0.07505176943622985 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 714 / 1000 | loss: 0.07496056567308908 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 715 / 1000 | loss: 0.07486957653710907 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 716 / 1000 | loss: 0.07477880124627942 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 717 / 1000 | loss: 0.07468823902256094 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 718 / 1000 | loss: 0.07459788909185788 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 719 / 1000 | loss: 0.07450775068399243 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 720 / 1000 | loss: 0.0744178230326802 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 721 / 1000 | loss: 0.07432810537550315 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 722 / 1000 | loss: 0.07423859695388518 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 723 / 1000 | loss: 0.07414929701306622 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 724 / 1000 | loss: 0.07406020480207867 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 725 / 1000 | loss: 0.07397131957372129 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 726 / 1000 | loss: 0.07388264058453535 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 727 / 1000 | loss: 0.07379416709478032 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 728 / 1000 | loss: 0.07370589836841036 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 729 / 1000 | loss: 0.07361783367304864 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 730 / 1000 | loss: 0.07352997227996542 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 731 / 1000 | loss: 0.07344231346405371 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 732 / 1000 | loss: 0.07335485650380598 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 733 / 1000 | loss: 0.0732676006812908 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 734 / 1000 | loss: 0.07318054528213036 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 735 / 1000 | loss: 0.07309368959547731 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 736 / 1000 | loss: 0.07300703291399209 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 737 / 1000 | loss: 0.07292057453382085 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 738 / 1000 | loss: 0.07283431375457255 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 739 / 1000 | loss: 0.07274824987929798 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 740 / 1000 | loss: 0.07266238221446585 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 741 / 1000 | loss: 0.07257671006994393 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 742 / 1000 | loss: 0.07249123275897432 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 743 / 1000 | loss: 0.0724059495981543 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 744 / 1000 | loss: 0.07232085990741464 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 745 / 1000 | loss: 0.07223596300999738 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 746 / 1000 | loss: 0.07215125823243673 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 747 / 1000 | loss: 0.07206674490453667 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 748 / 1000 | loss: 0.07198242235935123 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 749 / 1000 | loss: 0.07189828993316412 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 750 / 1000 | loss: 0.07181434696546793 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 751 / 1000 | loss: 0.07173059279894439 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 752 / 1000 | loss: 0.07164702677944433 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 753 / 1000 | loss: 0.07156364825596763 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 754 / 1000 | loss: 0.07148045658064467 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 755 / 1000 | loss: 0.07139745110871507 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 756 / 1000 | loss: 0.0713146311985092 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 757 / 1000 | loss: 0.07123199621142969 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 758 / 1000 | loss: 0.07114954551193109 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 759 / 1000 | loss: 0.07106727846750209 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 760 / 1000 | loss: 0.0709851944486456 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 761 / 1000 | loss: 0.07090329282886104 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 762 / 1000 | loss: 0.07082157298462585 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 763 / 1000 | loss: 0.07074003429537631 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 764 / 1000 | loss: 0.07065867614349013 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 765 / 1000 | loss: 0.07057749791426829 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 766 / 1000 | loss: 0.07049649899591678 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 767 / 1000 | loss: 0.07041567877952898 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 768 / 1000 | loss: 0.07033503665906793 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 769 / 1000 | loss: 0.0702545720313492 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 770 / 1000 | loss: 0.0701742842960228 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 771 / 1000 | loss: 0.07009417285555611 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 772 / 1000 | loss: 0.07001423711521788 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 773 / 1000 | loss: 0.06993447648305888 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 774 / 1000 | loss: 0.06985489036989763 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 775 / 1000 | loss: 0.06977547818930205 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 776 / 1000 | loss: 0.06969623935757245 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 777 / 1000 | loss: 0.06961717329372678 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 778 / 1000 | loss: 0.0695382794194828 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 779 / 1000 | loss: 0.06945955715924255 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 780 / 1000 | loss: 0.06938100594007515 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 781 / 1000 | loss: 0.06930262519170238 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 782 / 1000 | loss: 0.0692244143464815 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 783 / 1000 | loss: 0.06914637283939044 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 784 / 1000 | loss: 0.06906850010801097 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 785 / 1000 | loss: 0.06899079559251392 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 786 / 1000 | loss: 0.06891325873564402 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 787 / 1000 | loss: 0.06883588898270383 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 788 / 1000 | loss: 0.06875868578153851 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 789 / 1000 | loss: 0.06868164858252188 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 790 / 1000 | loss: 0.06860477683854006 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 791 / 1000 | loss: 0.0685280700049773 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 792 / 1000 | loss: 0.06845152753970105 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 793 / 1000 | loss: 0.06837514890304713 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 794 / 1000 | loss: 0.06829893355780575 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 795 / 1000 | loss: 0.06822288096920602 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 796 / 1000 | loss: 0.06814699060490297 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 797 / 1000 | loss: 0.0680712619349621 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 798 / 1000 | loss: 0.06799569443184568 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 799 / 1000 | loss: 0.06792028757039889 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 800 / 1000 | loss: 0.06784504082783552 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 801 / 1000 | loss: 0.06776995368372513 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 802 / 1000 | loss: 0.06769502561997712 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 803 / 1000 | loss: 0.06762025612082992 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 804 / 1000 | loss: 0.06754564467283496 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 805 / 1000 | loss: 0.06747119076484492 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 806 / 1000 | loss: 0.06739689388799949 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 807 / 1000 | loss: 0.06732275353571238 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 808 / 1000 | loss: 0.06724876920365866 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 809 / 1000 | loss: 0.06717494038975996 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 810 / 1000 | loss: 0.0671012665941742 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 811 / 1000 | loss: 0.0670277473192807 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 812 / 1000 | loss: 0.0669543820696675 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 813 / 1000 | loss: 0.06688117035211945 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 814 / 1000 | loss: 0.06680811167560537 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 815 / 1000 | loss: 0.06673520555126544 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 816 / 1000 | loss: 0.06666245149239836 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 817 / 1000 | loss: 0.06658984901444999 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 818 / 1000 | loss: 0.0665173976349999 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 819 / 1000 | loss: 0.06644509687375044 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 820 / 1000 | loss: 0.06637294625251353 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 821 / 1000 | loss: 0.0663009452951994 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 822 / 1000 | loss: 0.06622909352780405 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 823 / 1000 | loss: 0.06615739047839872 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 824 / 1000 | loss: 0.06608583567711626 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 825 / 1000 | loss: 0.06601442865614074 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 826 / 1000 | loss: 0.06594316894969583 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 827 / 1000 | loss: 0.06587205609403278 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 828 / 1000 | loss: 0.06580108962741921 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 829 / 1000 | loss: 0.06573026909012793 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 830 / 1000 | loss: 0.06565959402442553 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 831 / 1000 | loss: 0.06558906397456095 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 832 / 1000 | loss: 0.06551867848675494 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 833 / 1000 | loss: 0.06544843710918852 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 834 / 1000 | loss: 0.06537833939199243 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 835 / 1000 | loss: 0.06530838488723578 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 836 / 1000 | loss: 0.06523857314891558 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 837 / 1000 | loss: 0.06516890373294569 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 838 / 1000 | loss: 0.06509937619714701 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 839 / 1000 | loss: 0.06502999010123547 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 840 / 1000 | loss: 0.06496074500681287 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 841 / 1000 | loss: 0.06489164047735571 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 842 / 1000 | loss: 0.06482267607820504 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 843 / 1000 | loss: 0.06475385137655609 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 844 / 1000 | loss: 0.06468516594144791 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 845 / 1000 | loss: 0.06461661934375365 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 846 / 1000 | loss: 0.06454821115616975 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 847 / 1000 | loss: 0.06447994095320671 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 848 / 1000 | loss: 0.0644118083111788 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 849 / 1000 | loss: 0.064343812808194 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 850 / 1000 | loss: 0.0642759540241443 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 851 / 1000 | loss: 0.06420823154069585 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 852 / 1000 | loss: 0.06414064494127952 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 853 / 1000 | loss: 0.06407319381108126 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 854 / 1000 | loss: 0.06400587773703226 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 855 / 1000 | loss: 0.06393869630779965 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 856 / 1000 | loss: 0.06387164911377705 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 857 / 1000 | loss: 0.06380473574707507 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 858 / 1000 | loss: 0.06373795580151248 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 859 / 1000 | loss: 0.06367130887260615 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 860 / 1000 | loss: 0.06360479455756257 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 861 / 1000 | loss: 0.06353841245526841 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 862 / 1000 | loss: 0.06347216216628158 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 863 / 1000 | loss: 0.06340604329282233 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 864 / 1000 | loss: 0.06334005543876368 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 865 / 1000 | loss: 0.06327419820962359 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 866 / 1000 | loss: 0.0632084712125553 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 867 / 1000 | loss: 0.06314287405633857 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 868 / 1000 | loss: 0.06307740635137192 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 869 / 1000 | loss: 0.06301206770966283 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 870 / 1000 | loss: 0.06294685774481944 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 871 / 1000 | loss: 0.06288177607204264 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 872 / 1000 | loss: 0.06281682230811703 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 873 / 1000 | loss: 0.06275199607140247 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 874 / 1000 | loss: 0.06268729698182579 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 875 / 1000 | loss: 0.06262272466087279 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 876 / 1000 | loss: 0.06255827873157974 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 877 / 1000 | loss: 0.06249395881852484 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 878 / 1000 | loss: 0.06242976454782064 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 879 / 1000 | loss: 0.06236569554710582 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 880 / 1000 | loss: 0.06230175144553655 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 881 / 1000 | loss: 0.06223793187377948 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 882 / 1000 | loss: 0.06217423646400313 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 883 / 1000 | loss: 0.06211066484987011 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 884 / 1000 | loss: 0.06204721666652898 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 885 / 1000 | loss: 0.061983891550607635 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 886 / 1000 | loss: 0.06192068914020383 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 887 / 1000 | loss: 0.061857609074879145 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 888 / 1000 | loss: 0.06179465099565003 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 889 / 1000 | loss: 0.06173181454498114 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 890 / 1000 | loss: 0.061669099366777454 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 891 / 1000 | loss: 0.06160650510637666 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 892 / 1000 | loss: 0.061544031410541655 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 893 / 1000 | loss: 0.0614816779274535 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 894 / 1000 | loss: 0.06141944430670395 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 895 / 1000 | loss: 0.06135733019928795 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 896 / 1000 | loss: 0.06129533525759675 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 897 / 1000 | loss: 0.06123345913541004 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 898 / 1000 | loss: 0.06117170148788946 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 899 / 1000 | loss: 0.06111006197157145 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 900 / 1000 | loss: 0.06104854024435954 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 901 / 1000 | loss: 0.06098713596551799 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 902 / 1000 | loss: 0.06092584879566459 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 903 / 1000 | loss: 0.06086467839676331 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 904 / 1000 | loss: 0.06080362443211833 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 905 / 1000 | loss: 0.06074268656636619 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 906 / 1000 | loss: 0.06068186446546976 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 907 / 1000 | loss: 0.06062115779671082 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 908 / 1000 | loss: 0.06056056622868391 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 909 / 1000 | loss: 0.060500089431289435 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 910 / 1000 | loss: 0.06043972707572662 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 911 / 1000 | loss: 0.0603794788344878 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 912 / 1000 | loss: 0.060319344381350906 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 913 / 1000 | loss: 0.06025932339137365 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 914 / 1000 | loss: 0.060199415540886494 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 915 / 1000 | loss: 0.060139620507486766 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 916 / 1000 | loss: 0.06007993797003223 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 917 / 1000 | loss: 0.060020367608633884 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 918 / 1000 | loss: 0.059960909104650774 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 919 / 1000 | loss: 0.05990156214068312 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 920 / 1000 | loss: 0.05984232640056611 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 921 / 1000 | loss: 0.059783201569363745 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 922 / 1000 | loss: 0.05972418733336258 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 923 / 1000 | loss: 0.059665283380065846 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 924 / 1000 | loss: 0.059606489398187454 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 925 / 1000 | loss: 0.059547805077645545 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 926 / 1000 | loss: 0.05948923010955659 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 927 / 1000 | loss: 0.059430764186229654 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 928 / 1000 | loss: 0.059372407001160046 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 929 / 1000 | loss: 0.05931415824902402 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 930 / 1000 | loss: 0.05925601762567237 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 931 / 1000 | loss: 0.05919798482812479 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 932 / 1000 | loss: 0.059140059554564306 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 933 / 1000 | loss: 0.059082241504330904 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 934 / 1000 | loss: 0.05902453037791662 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 935 / 1000 | loss: 0.05896692587695934 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 936 / 1000 | loss: 0.05890942770423706 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 937 / 1000 | loss: 0.05885203556366255 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 938 / 1000 | loss: 0.05879474916027779 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 939 / 1000 | loss: 0.05873756820024845 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 940 / 1000 | loss: 0.05868049239085773 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 941 / 1000 | loss: 0.05862352144050194 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 942 / 1000 | loss: 0.05856665505868388 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 943 / 1000 | loss: 0.058509892956008835 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 944 / 1000 | loss: 0.058453234844177734 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 945 / 1000 | loss: 0.05839668043598262 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 946 / 1000 | loss: 0.05834022944530154 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 947 / 1000 | loss: 0.0582838815870922 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 948 / 1000 | loss: 0.05822763657738811 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 949 / 1000 | loss: 0.0581714941332919 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 950 / 1000 | loss: 0.05811545397297165 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 951 / 1000 | loss: 0.05805951581565446 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 952 / 1000 | loss: 0.05800367938162197 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 953 / 1000 | loss: 0.057947944392204916 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 954 / 1000 | loss: 0.057892310569778296 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 955 / 1000 | loss: 0.05783677763775675 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 956 / 1000 | loss: 0.05778134532058839 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 957 / 1000 | loss: 0.057726013343750916 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 958 / 1000 | loss: 0.05767078143374602 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 959 / 1000 | loss: 0.05761564931809496 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 960 / 1000 | loss: 0.057560616725332976 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 961 / 1000 | loss: 0.05750568338500571 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 962 / 1000 | loss: 0.057450849027662274 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 963 / 1000 | loss: 0.05739611338485288 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 964 / 1000 | loss: 0.0573414761891222 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 965 / 1000 | loss: 0.05728693717400549 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 966 / 1000 | loss: 0.057232496074023524 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 967 / 1000 | loss: 0.057178152624678215 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 968 / 1000 | loss: 0.05712390656244764 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 969 / 1000 | loss: 0.05706975762478178 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 970 / 1000 | loss: 0.05701570555009747 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 971 / 1000 | loss: 0.05696175007777365 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 972 / 1000 | loss: 0.05690789094814794 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 973 / 1000 | loss: 0.05685412790251087 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 974 / 1000 | loss: 0.05680046068310181 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 975 / 1000 | loss: 0.05674688903310491 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 976 / 1000 | loss: 0.05669341269664343 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 977 / 1000 | loss: 0.056640031418777055 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 978 / 1000 | loss: 0.056586744945495975 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 979 / 1000 | loss: 0.05653355302371763 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 980 / 1000 | loss: 0.056480455401281104 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 981 / 1000 | loss: 0.05642745182694444 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 982 / 1000 | loss: 0.05637454205037868 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 983 / 1000 | loss: 0.05632172582216495 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 984 / 1000 | loss: 0.056269002893788916 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 985 / 1000 | loss: 0.05621637301763779 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 986 / 1000 | loss: 0.05616383594699534 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 987 / 1000 | loss: 0.05611139143603828 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 988 / 1000 | loss: 0.05605903923983112 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 989 / 1000 | loss: 0.05600677911432343 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 990 / 1000 | loss: 0.055954610816344785 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 991 / 1000 | loss: 0.05590253410360047 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 992 / 1000 | loss: 0.055850548734668735 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 993 / 1000 | loss: 0.05579865446899489 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 994 / 1000 | loss: 0.05574685106688913 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 995 / 1000 | loss: 0.0556951382895211 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 996 / 1000 | loss: 0.05564351589891698 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 997 / 1000 | loss: 0.05559198365795457 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 998 / 1000 | loss: 0.05554054133036015 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 999 / 1000 | loss: 0.05548918868070455 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n",
      "Epoch: 1000 / 1000 | loss: 0.05543792547439876 | train accuracy: 100.0 % | test accuracy: 100.0 %.\n"
     ]
    }
   ],
   "source": [
    "model = Perceptron(2)\n",
    "model.train(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SNhb3cie-a5w"
   },
   "source": [
    "#### Perceptron w PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eI-gM4vha-YO"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class PerceptronTorch(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)     # jedna warstwa modelu - liniowa\n",
    "        self.sigm = nn.Sigmoid()                           # funkcja aktywacji sigmoidalna\n",
    "\n",
    "    def forward(self, x): \n",
    "        out = self.linear(x)                               # obliczanie wyjścia\n",
    "        out = self.sigm(out)                               # przeksztalcenie sigmoidalne\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_perceptron_torch():\n",
    "    \n",
    "    # Params\n",
    "    torch.manual_seed(717)\n",
    "    epochs = 1000\n",
    "    lr_rate = 0.01\n",
    "    \n",
    "    # Model\n",
    "    model = PerceptronTorch(input_dim = 2, output_dim = 1)\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = lr_rate)       \n",
    "    \n",
    "    # Loss\n",
    "    criterion = nn.MSELoss()                                             # funkcja mse jest analogiczna do funkcji straty\n",
    "                                                                         # z modelu pierwszego tylko nie przemnozona przez 0.5 co nie ma wplywu na gradient\n",
    "    # Train data\n",
    "    inputs = torch.from_numpy(X_train).view(-1,2).float()                # konwersja do float\n",
    "    labels = torch.from_numpy(y_train).float()                           # konwersja do float\n",
    "    \n",
    "    # Test data\n",
    "    inputs_test = torch.from_numpy(X_test).view(-1,2).float()            # konwersja do float\n",
    "    \n",
    "    # Train\n",
    "    for epoch in range(1, epochs + 1, 1):\n",
    "        \n",
    "        optimizer.zero_grad()                                            # wyczyszczenie gradientu\n",
    "        outputs = model(inputs)                                          # przeksztalcenie danych\n",
    "        \n",
    "        loss = criterion(outputs, labels.unsqueeze(1))                   # obliczenie loss\n",
    "        loss.backward()                                                  \n",
    "        \n",
    "        optimizer.step()                                                 # aktualizacja wag\n",
    "        \n",
    "        # Eval train\n",
    "        y_prob = model(inputs).detach().numpy()                          # predykcja\n",
    "        y_pred = [1 if y_ > 0.5 else 0 for y_ in y_prob]                 # obliczenie labels gdzie prog ustalam na 0.5\n",
    "        acc_train = sum([ y == y_ for y, y_ in zip(y_pred, y_train)]) / y_train.shape[0]\n",
    "        \n",
    "        # Evala test\n",
    "        y_prob_test = model(inputs_test).detach().numpy()                # predykcja\n",
    "        y_pred_test = [1 if y_ > 0.5 else 0 for y_ in y_prob_test]       # obliczenie labels gdzie prog ustalam na 0.5\n",
    "        acc_test= sum([ y == y_ for y, y_ in zip(y_pred_test, y_test)]) / y_test.shape[0]\n",
    "        \n",
    "        # Print results\n",
    "        print('epoch {} | loss {} | accuracy train {}% | accuracy test {}%'.format(epoch, loss.item(), round(acc_train * 100, 2), round(acc_test * 100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 | loss 0.643459677696228 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 2 | loss 0.6429001688957214 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 3 | loss 0.6423274278640747 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 4 | loss 0.6417413353919983 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 5 | loss 0.6411411762237549 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 6 | loss 0.6405264139175415 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 7 | loss 0.6398966312408447 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 8 | loss 0.6392513513565063 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 9 | loss 0.6385897397994995 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 10 | loss 0.6379114389419556 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 11 | loss 0.6372156143188477 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 12 | loss 0.6365017294883728 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 13 | loss 0.6357689499855042 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 14 | loss 0.6350165605545044 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 15 | loss 0.6342439651489258 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 16 | loss 0.6334500908851624 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 17 | loss 0.6326342225074768 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 18 | loss 0.6317955255508423 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 19 | loss 0.6309328079223633 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 20 | loss 0.6300452947616577 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 21 | loss 0.6291318535804749 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 22 | loss 0.628191351890564 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 23 | loss 0.6272227168083191 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 24 | loss 0.6262248158454895 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 25 | loss 0.6251961588859558 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 26 | loss 0.6241356134414673 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 27 | loss 0.6230417490005493 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 28 | loss 0.6219130754470825 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 29 | loss 0.6207482218742371 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 30 | loss 0.6195456385612488 | accuracy train 30.77% | accuracy test 16.67%\n",
      "epoch 31 | loss 0.618303656578064 | accuracy train 30.77% | accuracy test 16.67%\n",
      "epoch 32 | loss 0.6170206665992737 | accuracy train 30.77% | accuracy test 16.67%\n",
      "epoch 33 | loss 0.615695059299469 | accuracy train 30.77% | accuracy test 16.67%\n",
      "epoch 34 | loss 0.614325225353241 | accuracy train 30.77% | accuracy test 16.67%\n",
      "epoch 35 | loss 0.6129096150398254 | accuracy train 30.77% | accuracy test 16.67%\n",
      "epoch 36 | loss 0.6114464998245239 | accuracy train 30.77% | accuracy test 16.67%\n",
      "epoch 37 | loss 0.6099345684051514 | accuracy train 30.77% | accuracy test 16.67%\n",
      "epoch 38 | loss 0.6083725690841675 | accuracy train 30.77% | accuracy test 16.67%\n",
      "epoch 39 | loss 0.6067593693733215 | accuracy train 30.77% | accuracy test 16.67%\n",
      "epoch 40 | loss 0.6050946712493896 | accuracy train 30.77% | accuracy test 16.67%\n",
      "epoch 41 | loss 0.6033780574798584 | accuracy train 30.77% | accuracy test 16.67%\n",
      "epoch 42 | loss 0.601610541343689 | accuracy train 30.77% | accuracy test 16.67%\n",
      "epoch 43 | loss 0.5997936129570007 | accuracy train 30.77% | accuracy test 16.67%\n",
      "epoch 44 | loss 0.597930371761322 | accuracy train 30.77% | accuracy test 16.67%\n",
      "epoch 45 | loss 0.5960254073143005 | accuracy train 30.77% | accuracy test 16.67%\n",
      "epoch 46 | loss 0.5940850973129272 | accuracy train 30.77% | accuracy test 16.67%\n",
      "epoch 47 | loss 0.5921180248260498 | accuracy train 30.77% | accuracy test 16.67%\n",
      "epoch 48 | loss 0.5901351571083069 | accuracy train 30.77% | accuracy test 16.67%\n",
      "epoch 49 | loss 0.5881491303443909 | accuracy train 30.77% | accuracy test 16.67%\n",
      "epoch 50 | loss 0.5861737728118896 | accuracy train 30.77% | accuracy test 16.67%\n",
      "epoch 51 | loss 0.5842224955558777 | accuracy train 30.77% | accuracy test 16.67%\n",
      "epoch 52 | loss 0.5823066234588623 | accuracy train 30.77% | accuracy test 16.67%\n",
      "epoch 53 | loss 0.58043372631073 | accuracy train 30.77% | accuracy test 16.67%\n",
      "epoch 54 | loss 0.5786052942276001 | accuracy train 30.77% | accuracy test 16.67%\n",
      "epoch 55 | loss 0.5768172144889832 | accuracy train 30.77% | accuracy test 16.67%\n",
      "epoch 56 | loss 0.5750598311424255 | accuracy train 30.77% | accuracy test 16.67%\n",
      "epoch 57 | loss 0.5733201503753662 | accuracy train 30.77% | accuracy test 16.67%\n",
      "epoch 58 | loss 0.5715832114219666 | accuracy train 30.77% | accuracy test 16.67%\n",
      "epoch 59 | loss 0.5698347687721252 | accuracy train 30.77% | accuracy test 16.67%\n",
      "epoch 60 | loss 0.5680617690086365 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 61 | loss 0.5662535429000854 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 62 | loss 0.5644007921218872 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 63 | loss 0.5624964237213135 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 64 | loss 0.5605344176292419 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 65 | loss 0.5585094094276428 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 66 | loss 0.5564165711402893 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 67 | loss 0.5542515516281128 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 68 | loss 0.5520098209381104 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 69 | loss 0.5496866703033447 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 70 | loss 0.5472772717475891 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 71 | loss 0.5447766780853271 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 72 | loss 0.54217928647995 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 73 | loss 0.5394794940948486 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 74 | loss 0.5366706848144531 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 75 | loss 0.533746063709259 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 76 | loss 0.5306984186172485 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 77 | loss 0.5275193452835083 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 78 | loss 0.5242001414299011 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 79 | loss 0.5207309722900391 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 80 | loss 0.5171011686325073 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 81 | loss 0.5132985711097717 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 82 | loss 0.5093103051185608 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 83 | loss 0.5051212906837463 | accuracy train 30.77% | accuracy test 33.33%\n",
      "epoch 84 | loss 0.5007151961326599 | accuracy train 38.46% | accuracy test 33.33%\n",
      "epoch 85 | loss 0.4960730969905853 | accuracy train 38.46% | accuracy test 33.33%\n",
      "epoch 86 | loss 0.49117353558540344 | accuracy train 38.46% | accuracy test 33.33%\n",
      "epoch 87 | loss 0.4859923720359802 | accuracy train 38.46% | accuracy test 33.33%\n",
      "epoch 88 | loss 0.4805011749267578 | accuracy train 38.46% | accuracy test 33.33%\n",
      "epoch 89 | loss 0.47466710209846497 | accuracy train 38.46% | accuracy test 33.33%\n",
      "epoch 90 | loss 0.46845191717147827 | accuracy train 38.46% | accuracy test 33.33%\n",
      "epoch 91 | loss 0.46180978417396545 | accuracy train 38.46% | accuracy test 33.33%\n",
      "epoch 92 | loss 0.45468661189079285 | accuracy train 38.46% | accuracy test 33.33%\n",
      "epoch 93 | loss 0.44701671600341797 | accuracy train 38.46% | accuracy test 33.33%\n",
      "epoch 94 | loss 0.43872010707855225 | accuracy train 38.46% | accuracy test 33.33%\n",
      "epoch 95 | loss 0.4296978712081909 | accuracy train 38.46% | accuracy test 33.33%\n",
      "epoch 96 | loss 0.41982555389404297 | accuracy train 46.15% | accuracy test 33.33%\n",
      "epoch 97 | loss 0.40894219279289246 | accuracy train 46.15% | accuracy test 33.33%\n",
      "epoch 98 | loss 0.3968314528465271 | accuracy train 46.15% | accuracy test 33.33%\n",
      "epoch 99 | loss 0.383184015750885 | accuracy train 46.15% | accuracy test 33.33%\n",
      "epoch 100 | loss 0.36751696467399597 | accuracy train 53.85% | accuracy test 33.33%\n",
      "epoch 101 | loss 0.34898918867111206 | accuracy train 53.85% | accuracy test 33.33%\n",
      "epoch 102 | loss 0.32597634196281433 | accuracy train 53.85% | accuracy test 50.0%\n",
      "epoch 103 | loss 0.29526299238204956 | accuracy train 69.23% | accuracy test 50.0%\n",
      "epoch 104 | loss 0.2525283396244049 | accuracy train 84.62% | accuracy test 50.0%\n",
      "epoch 105 | loss 0.20499113202095032 | accuracy train 84.62% | accuracy test 50.0%\n",
      "epoch 106 | loss 0.17560434341430664 | accuracy train 92.31% | accuracy test 66.67%\n",
      "epoch 107 | loss 0.1595686376094818 | accuracy train 92.31% | accuracy test 66.67%\n",
      "epoch 108 | loss 0.14845487475395203 | accuracy train 92.31% | accuracy test 83.33%\n",
      "epoch 109 | loss 0.13983455300331116 | accuracy train 92.31% | accuracy test 100.0%\n",
      "epoch 110 | loss 0.13275623321533203 | accuracy train 92.31% | accuracy test 100.0%\n",
      "epoch 111 | loss 0.12674476206302643 | accuracy train 92.31% | accuracy test 100.0%\n",
      "epoch 112 | loss 0.12152798473834991 | accuracy train 92.31% | accuracy test 100.0%\n",
      "epoch 113 | loss 0.11693402379751205 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 114 | loss 0.11284573376178741 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 115 | loss 0.10917818546295166 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 116 | loss 0.10586683452129364 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 117 | loss 0.1028607040643692 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 118 | loss 0.10011867433786392 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 119 | loss 0.09760676324367523 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 120 | loss 0.09529665857553482 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 121 | loss 0.09316443651914597 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 122 | loss 0.09118974953889847 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 123 | loss 0.0893552377820015 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 124 | loss 0.08764591813087463 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 125 | loss 0.08604883402585983 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 126 | loss 0.08455275744199753 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 127 | loss 0.08314786851406097 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 128 | loss 0.0818256065249443 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 129 | loss 0.08057843148708344 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 130 | loss 0.07939967513084412 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 131 | loss 0.07828345894813538 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 132 | loss 0.07722456753253937 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 133 | loss 0.07621832191944122 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 134 | loss 0.07526056468486786 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 135 | loss 0.0743476003408432 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 136 | loss 0.07347604632377625 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 137 | loss 0.07264287769794464 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 138 | loss 0.07184541970491409 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 139 | loss 0.07108113914728165 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 140 | loss 0.0703478455543518 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 141 | loss 0.06964346766471863 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 142 | loss 0.06896615028381348 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 143 | loss 0.06831420212984085 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 144 | loss 0.06768607348203659 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 145 | loss 0.06708032637834549 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 146 | loss 0.06649564951658249 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 147 | loss 0.0659308135509491 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 148 | loss 0.06538473814725876 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 149 | loss 0.06485636532306671 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 150 | loss 0.06434474885463715 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 151 | loss 0.06384901702404022 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 152 | loss 0.06336832046508789 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 153 | loss 0.06290190666913986 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 154 | loss 0.06244908273220062 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 155 | loss 0.062009163200855255 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 156 | loss 0.061581529676914215 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 157 | loss 0.061165615916252136 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 158 | loss 0.060760870575904846 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 159 | loss 0.06036679074168205 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 160 | loss 0.059982892125844955 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 161 | loss 0.05960874259471893 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 162 | loss 0.05924389883875847 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 163 | loss 0.05888798087835312 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 164 | loss 0.058540623635053635 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 165 | loss 0.05820145830512047 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 166 | loss 0.057870153337717056 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 167 | loss 0.057546403259038925 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 168 | loss 0.057229913771152496 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 169 | loss 0.056920409202575684 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 170 | loss 0.0566176101565361 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 171 | loss 0.05632125958800316 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 172 | loss 0.056031133979558945 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 173 | loss 0.055747006088495255 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 174 | loss 0.055468663573265076 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 175 | loss 0.0551958829164505 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 176 | loss 0.0549284890294075 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 177 | loss 0.05466628819704056 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 178 | loss 0.05440910533070564 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 179 | loss 0.05415676534175873 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 180 | loss 0.053909122943878174 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 181 | loss 0.05366601422429085 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 182 | loss 0.05342729389667511 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 183 | loss 0.05319281667470932 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 184 | loss 0.05296246334910393 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 185 | loss 0.05273609608411789 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 186 | loss 0.052513591945171356 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 187 | loss 0.05229483172297478 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 188 | loss 0.05207972228527069 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 189 | loss 0.05186813324689865 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 190 | loss 0.0516599602997303 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 191 | loss 0.05145513266324997 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 192 | loss 0.05125352367758751 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 193 | loss 0.051055070012807846 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 194 | loss 0.05085964873433113 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 195 | loss 0.05066720396280289 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 196 | loss 0.05047765001654625 | accuracy train 100.0% | accuracy test 100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 197 | loss 0.050290901213884354 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 198 | loss 0.05010688677430153 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 199 | loss 0.0499255433678627 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 200 | loss 0.049746785312891006 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 201 | loss 0.04957055673003197 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 202 | loss 0.04939678683876991 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 203 | loss 0.04922541230916977 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 204 | loss 0.04905638471245766 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 205 | loss 0.048889633268117905 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 206 | loss 0.04872509464621544 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 207 | loss 0.04856274276971817 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 208 | loss 0.04840250313282013 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 209 | loss 0.04824433475732803 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 210 | loss 0.04808817803859711 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 211 | loss 0.047933995723724365 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 212 | loss 0.04778174310922623 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 213 | loss 0.04763136804103851 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 214 | loss 0.04748283326625824 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 215 | loss 0.04733610525727272 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 216 | loss 0.04719111695885658 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 217 | loss 0.04704786092042923 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 218 | loss 0.04690628871321678 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 219 | loss 0.04676635563373566 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 220 | loss 0.04662803187966347 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 221 | loss 0.04649128019809723 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 222 | loss 0.04635607451200485 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 223 | loss 0.046222373843193054 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 224 | loss 0.04609016329050064 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 225 | loss 0.04595939442515373 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 226 | loss 0.04583003371953964 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 227 | loss 0.04570208117365837 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 228 | loss 0.04557548463344574 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 229 | loss 0.045450225472450256 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 230 | loss 0.045326266437768936 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 231 | loss 0.045203592628240585 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 232 | loss 0.045082177966833115 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 233 | loss 0.04496200755238533 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 234 | loss 0.04484304040670395 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 235 | loss 0.04472526162862778 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 236 | loss 0.04460865259170532 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 237 | loss 0.0444931723177433 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 238 | loss 0.04437883943319321 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 239 | loss 0.04426559433341026 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 240 | loss 0.04415343701839447 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 241 | loss 0.04404233396053314 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 242 | loss 0.04393227770924568 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 243 | loss 0.04382326081395149 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 244 | loss 0.0437152236700058 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 245 | loss 0.04360819235444069 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 246 | loss 0.04350213706493378 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 247 | loss 0.04339704290032387 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 248 | loss 0.043292876332998276 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 249 | loss 0.043189637362957 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 250 | loss 0.04308730363845825 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 251 | loss 0.042985863983631134 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 252 | loss 0.042885299772024155 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 253 | loss 0.04278560355305672 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 254 | loss 0.042686767876148224 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 255 | loss 0.04258875176310539 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 256 | loss 0.04249156266450882 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 257 | loss 0.04239519312977791 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 258 | loss 0.042299605906009674 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 259 | loss 0.042204804718494415 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 260 | loss 0.042110785841941833 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 261 | loss 0.04201751574873924 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 262 | loss 0.04192499443888664 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 263 | loss 0.041833214461803436 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 264 | loss 0.04174215346574783 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 265 | loss 0.04165181890130043 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 266 | loss 0.04156217724084854 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 267 | loss 0.041473232209682465 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 268 | loss 0.04138496145606041 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 269 | loss 0.04129737615585327 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 270 | loss 0.04121045023202896 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 271 | loss 0.04112417995929718 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 272 | loss 0.04103855416178703 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 273 | loss 0.040953557938337326 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 274 | loss 0.040869180113077164 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 275 | loss 0.04078542813658714 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 276 | loss 0.04070228710770607 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 277 | loss 0.040619734674692154 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 278 | loss 0.04053778946399689 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 279 | loss 0.040456417948007584 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 280 | loss 0.04037562385201454 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 281 | loss 0.040295396000146866 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 282 | loss 0.04021572694182396 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 283 | loss 0.040136609226465225 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 284 | loss 0.040058035403490067 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 285 | loss 0.03997999429702759 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 286 | loss 0.03990248963236809 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 287 | loss 0.03982550650835037 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 288 | loss 0.03974904865026474 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 289 | loss 0.0396730937063694 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 290 | loss 0.039597637951374054 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 291 | loss 0.0395226813852787 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 292 | loss 0.03944821655750275 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 293 | loss 0.03937423601746559 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 294 | loss 0.03930073231458664 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 295 | loss 0.03922770544886589 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 296 | loss 0.03915514051914215 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 297 | loss 0.039083030074834824 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 298 | loss 0.0390113927423954 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 299 | loss 0.0389401912689209 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 300 | loss 0.03886943310499191 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 301 | loss 0.03879911080002785 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 302 | loss 0.038729228079319 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 303 | loss 0.038659777492284775 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 304 | loss 0.038590747863054276 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 305 | loss 0.03852212801575661 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 306 | loss 0.038453929126262665 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 307 | loss 0.038386132568120956 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 308 | loss 0.03831874579191208 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 309 | loss 0.03825175389647484 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 310 | loss 0.038185153156518936 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 311 | loss 0.03811895102262497 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 312 | loss 0.03805312141776085 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 313 | loss 0.037987686693668365 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 314 | loss 0.03792262449860573 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 315 | loss 0.03785793483257294 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 316 | loss 0.0377936027944088 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 317 | loss 0.037729647010564804 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 318 | loss 0.03766604885458946 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 319 | loss 0.03760279715061188 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 320 | loss 0.03753991425037384 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 321 | loss 0.037477362900972366 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 322 | loss 0.03741516172885895 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 323 | loss 0.03735329955816269 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 324 | loss 0.03729178011417389 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 325 | loss 0.037230588495731354 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 326 | loss 0.037169743329286575 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 327 | loss 0.03710921108722687 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 328 | loss 0.03704899922013283 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 329 | loss 0.03698911517858505 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 330 | loss 0.03692954033613205 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 331 | loss 0.03687029331922531 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 332 | loss 0.03681134432554245 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 333 | loss 0.036752697080373764 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 334 | loss 0.03669435903429985 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 335 | loss 0.03663633018732071 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 336 | loss 0.03657858818769455 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 337 | loss 0.036521151661872864 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 338 | loss 0.036463990807533264 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 339 | loss 0.03640712425112724 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 340 | loss 0.0363505519926548 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 341 | loss 0.036294255405664444 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 342 | loss 0.03623824566602707 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 343 | loss 0.03618251532316208 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 344 | loss 0.03612705320119858 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 345 | loss 0.036071863025426865 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 346 | loss 0.03601694479584694 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 347 | loss 0.0359623059630394 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 348 | loss 0.03590790927410126 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 349 | loss 0.0358537882566452 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 350 | loss 0.035799916833639145 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 351 | loss 0.03574632108211517 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 352 | loss 0.0356929637491703 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 353 | loss 0.03563986346125603 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 354 | loss 0.035587016493082047 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 355 | loss 0.035534415394067764 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 356 | loss 0.03548206388950348 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 357 | loss 0.035429947078228 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 358 | loss 0.03537808731198311 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 359 | loss 0.03532644361257553 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 360 | loss 0.03527504950761795 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 361 | loss 0.03522389754652977 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 362 | loss 0.0351729616522789 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 363 | loss 0.03512226790189743 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 364 | loss 0.03507179394364357 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 365 | loss 0.03502155840396881 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 366 | loss 0.034971531480550766 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 367 | loss 0.03492174297571182 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 368 | loss 0.03487216308712959 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 369 | loss 0.03482281416654587 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 370 | loss 0.03477366268634796 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 371 | loss 0.034724749624729156 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 372 | loss 0.03467603772878647 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 373 | loss 0.03462753817439079 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 374 | loss 0.03457925096154213 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 375 | loss 0.034531161189079285 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 376 | loss 0.034483280032873154 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 377 | loss 0.034435611218214035 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 378 | loss 0.03438814729452133 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 379 | loss 0.03434087336063385 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 380 | loss 0.03429379686713219 | accuracy train 100.0% | accuracy test 100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 381 | loss 0.03424692526459694 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 382 | loss 0.03420025855302811 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 383 | loss 0.0341537743806839 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 384 | loss 0.03410749137401581 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 385 | loss 0.034061383455991745 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 386 | loss 0.0340154804289341 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 387 | loss 0.033969756215810776 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 388 | loss 0.033924221992492676 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 389 | loss 0.033878885209560394 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 390 | loss 0.03383371978998184 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 391 | loss 0.033788736909627914 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 392 | loss 0.03374393656849861 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 393 | loss 0.033699311316013336 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 394 | loss 0.033654872328042984 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 395 | loss 0.03361060842871666 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 396 | loss 0.033566512167453766 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 397 | loss 0.0335225909948349 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 398 | loss 0.03347884863615036 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 399 | loss 0.03343527391552925 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 400 | loss 0.03339187055826187 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 401 | loss 0.03334864228963852 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 402 | loss 0.0333055704832077 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 403 | loss 0.03326266631484032 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 404 | loss 0.03321993723511696 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 405 | loss 0.03317736089229584 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 406 | loss 0.03313494846224785 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 407 | loss 0.03309269994497299 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 408 | loss 0.03305061534047127 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 409 | loss 0.03300867974758148 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 410 | loss 0.03296690806746483 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 411 | loss 0.03292529284954071 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 412 | loss 0.03288382664322853 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 413 | loss 0.03284252807497978 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 414 | loss 0.03280136361718178 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 415 | loss 0.032760366797447205 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 416 | loss 0.03271951898932457 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 417 | loss 0.03267882019281387 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 418 | loss 0.03263826668262482 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 419 | loss 0.032597865909338 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 420 | loss 0.03255760669708252 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 421 | loss 0.03251749649643898 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 422 | loss 0.032477524131536484 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 423 | loss 0.032437704503536224 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 424 | loss 0.032398026436567307 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 425 | loss 0.03235848993062973 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 426 | loss 0.032319094985723495 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 427 | loss 0.032279834151268005 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 428 | loss 0.03224071115255356 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 429 | loss 0.03220174089074135 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 430 | loss 0.03216289356350899 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 431 | loss 0.03212418407201767 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 432 | loss 0.032085612416267395 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 433 | loss 0.032047174870967865 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 434 | loss 0.032008860260248184 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 435 | loss 0.03197069466114044 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 436 | loss 0.03193264827132225 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 437 | loss 0.0318947359919548 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 438 | loss 0.031856946647167206 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 439 | loss 0.03181930631399155 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 440 | loss 0.031781770288944244 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 441 | loss 0.031744375824928284 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 442 | loss 0.03170711174607277 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 443 | loss 0.03166995942592621 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 444 | loss 0.031632937490940094 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 445 | loss 0.031596045941114426 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 446 | loss 0.03155927360057831 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 447 | loss 0.03152262046933174 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 448 | loss 0.031486086547374725 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 449 | loss 0.03144967555999756 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 450 | loss 0.03141338378190994 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 451 | loss 0.031377218663692474 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 452 | loss 0.03134116530418396 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 453 | loss 0.031305231153964996 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 454 | loss 0.031269416213035583 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 455 | loss 0.031233711168169975 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 456 | loss 0.031198136508464813 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 457 | loss 0.031162651255726814 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 458 | loss 0.03112730197608471 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 459 | loss 0.03109206072986126 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 460 | loss 0.031056933104991913 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 461 | loss 0.03102191537618637 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 462 | loss 0.030986998230218887 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 463 | loss 0.03095220774412155 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 464 | loss 0.030917521566152573 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 465 | loss 0.0308829415589571 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 466 | loss 0.03084847331047058 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 467 | loss 0.030814114958047867 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 468 | loss 0.030779864639043808 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 469 | loss 0.030745714902877808 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 470 | loss 0.03071167878806591 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 471 | loss 0.030677732080221176 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 472 | loss 0.03064390830695629 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 473 | loss 0.030610183253884315 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 474 | loss 0.030576560646295547 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 475 | loss 0.030543046072125435 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 476 | loss 0.030509622767567635 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 477 | loss 0.030476300045847893 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 478 | loss 0.030443094670772552 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 479 | loss 0.030409980565309525 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 480 | loss 0.03037695772945881 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 481 | loss 0.030344046652317047 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 482 | loss 0.030311228707432747 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 483 | loss 0.0302785225212574 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 484 | loss 0.030245903879404068 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 485 | loss 0.030213382095098495 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 486 | loss 0.030180957168340683 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 487 | loss 0.030148625373840332 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 488 | loss 0.03011639043688774 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 489 | loss 0.03008425422012806 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 490 | loss 0.030052201822400093 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 491 | loss 0.030020250007510185 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 492 | loss 0.029988396912813187 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 493 | loss 0.029956622049212456 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 494 | loss 0.02992495708167553 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 495 | loss 0.029893379658460617 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 496 | loss 0.029861893504858017 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 497 | loss 0.029830489307641983 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 498 | loss 0.029799185693264008 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 499 | loss 0.029767969623208046 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 500 | loss 0.02973683923482895 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 501 | loss 0.02970580942928791 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 502 | loss 0.02967485785484314 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 503 | loss 0.029643986374139786 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 504 | loss 0.02961321547627449 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 505 | loss 0.02958252653479576 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 506 | loss 0.029551925137639046 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 507 | loss 0.029521409422159195 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 508 | loss 0.029490984976291656 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 509 | loss 0.029460636898875237 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 510 | loss 0.02943037822842598 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 511 | loss 0.02940019965171814 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 512 | loss 0.029370106756687164 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 513 | loss 0.029340101405978203 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 514 | loss 0.029310178011655807 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 515 | loss 0.029280338436365128 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 516 | loss 0.029250578954815865 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 517 | loss 0.02922089211642742 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 518 | loss 0.02919129654765129 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 519 | loss 0.029161779209971428 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 520 | loss 0.029132336378097534 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 521 | loss 0.029102982953190804 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 522 | loss 0.029073702171444893 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 523 | loss 0.029044510796666145 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 524 | loss 0.02901539020240307 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 525 | loss 0.028986351564526558 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 526 | loss 0.028957389295101166 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 527 | loss 0.028928499668836594 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 528 | loss 0.028899699449539185 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 529 | loss 0.028870970010757446 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 530 | loss 0.02884230948984623 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 531 | loss 0.02881372906267643 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 532 | loss 0.02878522500395775 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 533 | loss 0.028756804764270782 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 534 | loss 0.028728444129228592 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 535 | loss 0.028700171038508415 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 536 | loss 0.028671961277723312 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 537 | loss 0.028643829748034477 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 538 | loss 0.028615768998861313 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 539 | loss 0.02858779951930046 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 540 | loss 0.028559880331158638 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 541 | loss 0.028532041236758232 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 542 | loss 0.028504272922873497 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 543 | loss 0.02847658284008503 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 544 | loss 0.028448956087231636 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 545 | loss 0.02842140570282936 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 546 | loss 0.028393924236297607 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 547 | loss 0.028366513550281525 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 548 | loss 0.028339169919490814 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 549 | loss 0.028311897069215775 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 550 | loss 0.028284700587391853 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 551 | loss 0.02825755998492241 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 552 | loss 0.02823049947619438 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 553 | loss 0.028203504160046577 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 554 | loss 0.028176575899124146 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 555 | loss 0.028149714693427086 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 556 | loss 0.0281229205429554 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 557 | loss 0.028096191585063934 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 558 | loss 0.02806953713297844 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 559 | loss 0.02804294414818287 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 560 | loss 0.02801642008125782 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 561 | loss 0.027989951893687248 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 562 | loss 0.027963560074567795 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 563 | loss 0.027937231585383415 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 564 | loss 0.02791096456348896 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 565 | loss 0.027884772047400475 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 566 | loss 0.027858631685376167 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 567 | loss 0.02783256024122238 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 568 | loss 0.02780654840171337 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 569 | loss 0.027780601754784584 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 570 | loss 0.02775472216308117 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 571 | loss 0.02772889845073223 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 572 | loss 0.02770315296947956 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 573 | loss 0.027677446603775024 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 574 | loss 0.027651820331811905 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 575 | loss 0.02762625552713871 | accuracy train 100.0% | accuracy test 100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 576 | loss 0.027600746601819992 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 577 | loss 0.02757529355585575 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 578 | loss 0.02754991129040718 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 579 | loss 0.027524586766958237 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 580 | loss 0.027499327436089516 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 581 | loss 0.027474109083414078 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 582 | loss 0.027448970824480057 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 583 | loss 0.027423886582255363 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 584 | loss 0.02739885449409485 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 585 | loss 0.027373891323804855 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 586 | loss 0.027348985895514488 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 587 | loss 0.027324143797159195 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 588 | loss 0.027299344539642334 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 589 | loss 0.027274610474705696 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 590 | loss 0.027249939739704132 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 591 | loss 0.0272253155708313 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 592 | loss 0.02720075659453869 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 593 | loss 0.027176251634955406 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 594 | loss 0.027151810005307198 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 595 | loss 0.02712741680443287 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 596 | loss 0.027103083208203316 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 597 | loss 0.027078811079263687 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 598 | loss 0.02705458737909794 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 599 | loss 0.02703043445944786 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 600 | loss 0.02700631506741047 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 601 | loss 0.0269822645932436 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 602 | loss 0.02695826068520546 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 603 | loss 0.0269343089312315 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 604 | loss 0.02691042423248291 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 605 | loss 0.02688658982515335 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 606 | loss 0.026862801983952522 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 607 | loss 0.026839084923267365 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 608 | loss 0.02681540511548519 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 609 | loss 0.026791784912347794 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 610 | loss 0.026768215000629425 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 611 | loss 0.026744702830910683 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 612 | loss 0.026721246540546417 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 613 | loss 0.026697834953665733 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 614 | loss 0.026674481108784676 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 615 | loss 0.02665117010474205 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 616 | loss 0.02662791684269905 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 617 | loss 0.02660471200942993 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 618 | loss 0.026581566780805588 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 619 | loss 0.026558471843600273 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 620 | loss 0.02653541788458824 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 621 | loss 0.026512425392866135 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 622 | loss 0.026489483192563057 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 623 | loss 0.026466578245162964 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 624 | loss 0.026443736627697945 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 625 | loss 0.026420943439006805 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 626 | loss 0.026398194953799248 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 627 | loss 0.02637549862265587 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 628 | loss 0.026352854445576668 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 629 | loss 0.026330258697271347 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 630 | loss 0.02630770578980446 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 631 | loss 0.026285208761692047 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 632 | loss 0.026262758299708366 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 633 | loss 0.026240361854434013 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 634 | loss 0.026218004524707794 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 635 | loss 0.026195693761110306 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 636 | loss 0.026173442602157593 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 637 | loss 0.026151228696107864 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 638 | loss 0.026129065081477165 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 639 | loss 0.026106955483555794 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 640 | loss 0.026084881275892258 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 641 | loss 0.0260628629475832 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 642 | loss 0.026040898635983467 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 643 | loss 0.026018967851996422 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 644 | loss 0.025997081771492958 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 645 | loss 0.02597525343298912 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 646 | loss 0.02595346048474312 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 647 | loss 0.025931717827916145 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 648 | loss 0.025910023599863052 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 649 | loss 0.02588837221264839 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 650 | loss 0.025866763666272163 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 651 | loss 0.025845209136605263 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 652 | loss 0.02582368068397045 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 653 | loss 0.02580222487449646 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 654 | loss 0.025780797004699707 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 655 | loss 0.025759411975741386 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 656 | loss 0.025738079100847244 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 657 | loss 0.025716783478856087 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 658 | loss 0.025695540010929108 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 659 | loss 0.025674333795905113 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 660 | loss 0.025653179734945297 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 661 | loss 0.02563205361366272 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 662 | loss 0.02561098523437977 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 663 | loss 0.0255899541079998 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 664 | loss 0.02556896023452282 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 665 | loss 0.025548018515110016 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 666 | loss 0.025527115911245346 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 667 | loss 0.025506261736154556 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 668 | loss 0.025485439226031303 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 669 | loss 0.02546466514468193 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 670 | loss 0.025443939492106438 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 671 | loss 0.02542324736714363 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 672 | loss 0.025402603670954704 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 673 | loss 0.02538199909031391 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 674 | loss 0.025361428037285805 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 675 | loss 0.025340907275676727 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 676 | loss 0.025320427492260933 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 677 | loss 0.02529999241232872 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 678 | loss 0.025279585272073746 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 679 | loss 0.02525922656059265 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 680 | loss 0.02523891068994999 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 681 | loss 0.025218626484274864 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 682 | loss 0.02519839257001877 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 683 | loss 0.02517819218337536 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 684 | loss 0.025158043950796127 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 685 | loss 0.025137929245829582 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 686 | loss 0.025117844343185425 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 687 | loss 0.025097813457250595 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 688 | loss 0.025077810510993004 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 689 | loss 0.02505785971879959 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 690 | loss 0.025037940591573715 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 691 | loss 0.025018049404025078 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 692 | loss 0.024998214095830917 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 693 | loss 0.02497841604053974 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 694 | loss 0.0249586533755064 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 695 | loss 0.024938922375440598 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 696 | loss 0.024919234216213226 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 697 | loss 0.024899590760469437 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 698 | loss 0.024879980832338333 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 699 | loss 0.024860411882400513 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 700 | loss 0.02484087273478508 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 701 | loss 0.02482137829065323 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 702 | loss 0.02480192855000496 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 703 | loss 0.02478250488638878 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 704 | loss 0.024763120338320732 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 705 | loss 0.02474377304315567 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 706 | loss 0.024724463000893593 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 707 | loss 0.02470518834888935 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 708 | loss 0.02468596212565899 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 709 | loss 0.024666763842105865 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 710 | loss 0.024647610262036324 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 711 | loss 0.024628479033708572 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 712 | loss 0.024609388783574104 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 713 | loss 0.02459033951163292 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 714 | loss 0.02457132190465927 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 715 | loss 0.024552341550588608 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 716 | loss 0.024533400312066078 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 717 | loss 0.024514487013220787 | accuracy train 100.0% | accuracy test 100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 718 | loss 0.02449561282992363 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 719 | loss 0.024476779624819756 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 720 | loss 0.024457979947328568 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 721 | loss 0.024439215660095215 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 722 | loss 0.02442047744989395 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 723 | loss 0.024401787668466568 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 724 | loss 0.024383125826716423 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 725 | loss 0.024364501237869263 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 726 | loss 0.024345913901925087 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 727 | loss 0.02432735078036785 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 728 | loss 0.024308834224939346 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 729 | loss 0.02429034933447838 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 730 | loss 0.024271896108984947 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 731 | loss 0.024253476411104202 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 732 | loss 0.024235090240836143 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 733 | loss 0.024216745048761368 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 734 | loss 0.024198420345783234 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 735 | loss 0.024180134758353233 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 736 | loss 0.024161888286471367 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 737 | loss 0.024143677204847336 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 738 | loss 0.02412549965083599 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 739 | loss 0.02410734072327614 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 740 | loss 0.024089230224490166 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 741 | loss 0.02407114952802658 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 742 | loss 0.024053098633885384 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 743 | loss 0.024035077542066574 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 744 | loss 0.0240170918405056 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 745 | loss 0.02399914711713791 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 746 | loss 0.02398122474551201 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 747 | loss 0.023963332176208496 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 748 | loss 0.023945491760969162 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 749 | loss 0.023927662521600723 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 750 | loss 0.023909879848361015 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 751 | loss 0.023892121389508247 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 752 | loss 0.023874394595623016 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 753 | loss 0.02385670877993107 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 754 | loss 0.023839043453335762 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 755 | loss 0.02382141724228859 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 756 | loss 0.023803817108273506 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 757 | loss 0.02378624677658081 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 758 | loss 0.0237687136977911 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 759 | loss 0.023751210421323776 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 760 | loss 0.02373373694717884 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 761 | loss 0.02371629886329174 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 762 | loss 0.02369888685643673 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 763 | loss 0.023681508377194405 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 764 | loss 0.02366415411233902 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 765 | loss 0.023646844550967216 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 766 | loss 0.023629555478692055 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 767 | loss 0.023612292483448982 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 768 | loss 0.023595072329044342 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 769 | loss 0.023577867075800896 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 770 | loss 0.02356071211397648 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 771 | loss 0.023543573915958405 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 772 | loss 0.023526469245553017 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 773 | loss 0.023509390652179718 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 774 | loss 0.023492353036999702 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 775 | loss 0.02347533032298088 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 776 | loss 0.023458348587155342 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 777 | loss 0.023441385477781296 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 778 | loss 0.02342446707189083 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 779 | loss 0.023407557979226112 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 780 | loss 0.023390697315335274 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 781 | loss 0.023373862728476524 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 782 | loss 0.023357046768069267 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 783 | loss 0.023340271785855293 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 784 | loss 0.023323509842157364 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 785 | loss 0.023306794464588165 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 786 | loss 0.02329009771347046 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 787 | loss 0.02327343076467514 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 788 | loss 0.02325679175555706 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 789 | loss 0.023240189999341965 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 790 | loss 0.02322361245751381 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 791 | loss 0.023207059130072594 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 792 | loss 0.023190539330244064 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 793 | loss 0.023174036294221878 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 794 | loss 0.023157576099038124 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 795 | loss 0.02314113639295101 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 796 | loss 0.023124732077121735 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 797 | loss 0.02310834638774395 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 798 | loss 0.02309199422597885 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 799 | loss 0.023075660690665245 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 800 | loss 0.023059368133544922 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 801 | loss 0.02304309420287609 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 802 | loss 0.023026850074529648 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 803 | loss 0.023010633885860443 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 804 | loss 0.022994449362158775 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 805 | loss 0.0229782797396183 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 806 | loss 0.022962139919400215 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 807 | loss 0.022946033626794815 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 808 | loss 0.022929953411221504 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 809 | loss 0.02291390486061573 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 810 | loss 0.0228978730738163 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 811 | loss 0.022881872951984406 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 812 | loss 0.0228659026324749 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 813 | loss 0.022849950939416885 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 814 | loss 0.022834034636616707 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 815 | loss 0.02281814068555832 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 816 | loss 0.02280227281153202 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 817 | loss 0.022786427289247513 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 818 | loss 0.02277061715722084 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 819 | loss 0.02275482565164566 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 820 | loss 0.022739073261618614 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 821 | loss 0.022723328322172165 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 822 | loss 0.02270761877298355 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 823 | loss 0.022691935300827026 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 824 | loss 0.02267627976834774 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 825 | loss 0.022660650312900543 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 826 | loss 0.022645043209195137 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 827 | loss 0.022629452869296074 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 828 | loss 0.022613903507590294 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 829 | loss 0.022598376497626305 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 830 | loss 0.022582868114113808 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 831 | loss 0.0225673895329237 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 832 | loss 0.02255193330347538 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 833 | loss 0.02253650687634945 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 834 | loss 0.02252110466361046 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 835 | loss 0.022505726665258408 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 836 | loss 0.0224903654307127 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 837 | loss 0.02247503586113453 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 838 | loss 0.022459736093878746 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 839 | loss 0.022444454953074455 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 840 | loss 0.022429198026657104 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 841 | loss 0.022413967177271843 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 842 | loss 0.02239876613020897 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 843 | loss 0.022383587434887886 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 844 | loss 0.022368427366018295 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 845 | loss 0.02235329896211624 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 846 | loss 0.02233818918466568 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 847 | loss 0.02232310175895691 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 848 | loss 0.022308042272925377 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 849 | loss 0.022293012589216232 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 850 | loss 0.02227799966931343 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 851 | loss 0.02226301282644272 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 852 | loss 0.022248048335313797 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 853 | loss 0.022233106195926666 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 854 | loss 0.022218190133571625 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 855 | loss 0.022203298285603523 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 856 | loss 0.02218843251466751 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 857 | loss 0.022173592820763588 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 858 | loss 0.02215876802802086 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 859 | loss 0.022143973037600517 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 860 | loss 0.02212919481098652 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 861 | loss 0.022114446386694908 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 862 | loss 0.022099711000919342 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 863 | loss 0.02208501100540161 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 864 | loss 0.022070327773690224 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 865 | loss 0.022055665031075478 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 866 | loss 0.02204103022813797 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 867 | loss 0.022026427090168 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 868 | loss 0.02201182395219803 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 869 | loss 0.02199726179242134 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 870 | loss 0.021982721984386444 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 871 | loss 0.02196819707751274 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 872 | loss 0.021953701972961426 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 873 | loss 0.021939227357506752 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 874 | loss 0.021924767643213272 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 875 | loss 0.021910343319177628 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 876 | loss 0.021895932033658028 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 877 | loss 0.021881546825170517 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 878 | loss 0.02186717838048935 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 879 | loss 0.02185283787548542 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 880 | loss 0.021838517859578133 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 881 | loss 0.021824222058057785 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 882 | loss 0.021809952333569527 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 883 | loss 0.021795690059661865 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 884 | loss 0.02178146317601204 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 885 | loss 0.021767256781458855 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 886 | loss 0.021753061562776566 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 887 | loss 0.021738896146416664 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 888 | loss 0.021724758669734 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 889 | loss 0.02171063795685768 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 890 | loss 0.021696537733078003 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 891 | loss 0.02168245054781437 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 892 | loss 0.02166840061545372 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 893 | loss 0.02165435627102852 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 894 | loss 0.02164035104215145 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 895 | loss 0.021626349538564682 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 896 | loss 0.02161238342523575 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 897 | loss 0.02159843221306801 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 898 | loss 0.02158450148999691 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 899 | loss 0.021570589393377304 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 900 | loss 0.021556703373789787 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 901 | loss 0.02154283970594406 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 902 | loss 0.02152899093925953 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 903 | loss 0.021515170112252235 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 904 | loss 0.021501364186406136 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 905 | loss 0.021487586200237274 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 906 | loss 0.021473823115229607 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 907 | loss 0.021460074931383133 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 908 | loss 0.021446360275149345 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 909 | loss 0.02143266424536705 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 910 | loss 0.021418975666165352 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 911 | loss 0.02140531875193119 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 912 | loss 0.02139168791472912 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 913 | loss 0.021378062665462494 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 914 | loss 0.02136446349322796 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 915 | loss 0.021350888535380363 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 916 | loss 0.021337322890758514 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 917 | loss 0.0213237926363945 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 918 | loss 0.02131027728319168 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 919 | loss 0.021296778693795204 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 920 | loss 0.021283308044075966 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 921 | loss 0.021269841119647026 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 922 | loss 0.02125640958547592 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 923 | loss 0.02124299667775631 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 924 | loss 0.021229587495326996 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 925 | loss 0.021216213703155518 | accuracy train 100.0% | accuracy test 100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 926 | loss 0.02120286040008068 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 927 | loss 0.02118951827287674 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 928 | loss 0.021176205947995186 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 929 | loss 0.021162908524274826 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 930 | loss 0.021149618551135063 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 931 | loss 0.021136363968253136 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 932 | loss 0.021123124286532402 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 933 | loss 0.02110990509390831 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 934 | loss 0.02109670452773571 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 935 | loss 0.021083520725369453 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 936 | loss 0.02107035368680954 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 937 | loss 0.021057220175862312 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 938 | loss 0.021044086664915085 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 939 | loss 0.021030982956290245 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 940 | loss 0.021017897874116898 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 941 | loss 0.021004829555749893 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 942 | loss 0.02099178172647953 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 943 | loss 0.020978756248950958 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 944 | loss 0.02096574567258358 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 945 | loss 0.020952751860022545 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 946 | loss 0.0209397803992033 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 947 | loss 0.0209268257021904 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 948 | loss 0.020913895219564438 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 949 | loss 0.020900974050164223 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 950 | loss 0.020888082683086395 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 951 | loss 0.020875195041298866 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 952 | loss 0.020862339064478874 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 953 | loss 0.020849499851465225 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 954 | loss 0.02083667740225792 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 955 | loss 0.02082386612892151 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 956 | loss 0.020811088383197784 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 957 | loss 0.02079830691218376 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 958 | loss 0.020785562694072723 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 959 | loss 0.02077282778918743 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 960 | loss 0.02076011709868908 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 961 | loss 0.02074742130935192 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 962 | loss 0.020734736695885658 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 963 | loss 0.02072208933532238 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 964 | loss 0.020709441974759102 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 965 | loss 0.020696818828582764 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 966 | loss 0.02068420872092247 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 967 | loss 0.020671626552939415 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 968 | loss 0.020659049972891808 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 969 | loss 0.02064650133252144 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 970 | loss 0.02063397318124771 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 971 | loss 0.02062145061790943 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 972 | loss 0.020608952268958092 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 973 | loss 0.020596472546458244 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 974 | loss 0.02058400586247444 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 975 | loss 0.02057155966758728 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 976 | loss 0.02055913209915161 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 977 | loss 0.020546721294522285 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 978 | loss 0.02053433284163475 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 979 | loss 0.020521951839327812 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 980 | loss 0.020509587600827217 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 981 | loss 0.02049725502729416 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 982 | loss 0.020484931766986847 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 983 | loss 0.02047261781990528 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 984 | loss 0.020460335537791252 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 985 | loss 0.02044806070625782 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 986 | loss 0.020435800775885582 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 987 | loss 0.020423561334609985 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 988 | loss 0.02041134610772133 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 989 | loss 0.02039913646876812 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 990 | loss 0.02038695104420185 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 991 | loss 0.020374778658151627 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 992 | loss 0.020362624898552895 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 993 | loss 0.020350487902760506 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 994 | loss 0.020338373258709908 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 995 | loss 0.020326267927885056 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 996 | loss 0.020314179360866547 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 997 | loss 0.02030211314558983 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 998 | loss 0.020290056243538857 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 999 | loss 0.020278016105294228 | accuracy train 100.0% | accuracy test 100.0%\n",
      "epoch 1000 | loss 0.020266003906726837 | accuracy train 100.0% | accuracy test 100.0%\n"
     ]
    }
   ],
   "source": [
    "train_perceptron_torch()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "WUM2z.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
